{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "painful-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import gc\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from math import e\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv3D, Flatten,MaxPooling3D,AveragePooling3D, concatenate,Input ,SpatialDropout3D,Dropout\n",
    "from sklearn import metrics\n",
    "from keras import backend as K\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.constraints import unit_norm\n",
    "\n",
    "import proplot as pplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bottom-jewel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: /physical_device:GPU:0   Type: GPU\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)\n",
    "    \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "narrow-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing functions\n",
    "#3D detrend function\n",
    "def detrend(x:np.ndarray,time:np.ndarray):\n",
    "        nt,nx,ny = x.shape\n",
    "        xtemp = x.reshape(nt,nx*ny)\n",
    "        p = np.polyfit(time, xtemp, deg=3)\n",
    "        fit = p[0]*(time[:,np.newaxis] **3)+ p[1]*(time[:,np.newaxis]**2) + p[2]*(time[:,np.newaxis]) + p[3]\n",
    "        return x - fit.reshape(nt,nx,ny)\n",
    "\n",
    "#1D detrend function\n",
    "def altdetrend(x:np.ndarray,time:np.ndarray):\n",
    "        nt = x.shape\n",
    "        xtemp = x.reshape(nt)\n",
    "        p = np.polyfit(time, x, deg=1)\n",
    "        fit = p[0]*(time[:,np.newaxis])+ p[1]\n",
    "        return x - fit.reshape(nt)\n",
    "    \n",
    "def remove_time_mean(x):\n",
    "        return x - x.mean(dim='time')\n",
    "\n",
    "def removeSC(x):\n",
    "        return x.groupby('time.month').apply(remove_time_mean)\n",
    "\n",
    "# Calculate std normal anomaly\n",
    "def calStdNorAnom(x):\n",
    "    a=[]\n",
    "    for m in np.unique(x.time.dt.month):\n",
    "        mData=x[x.time.dt.month==m]\n",
    "        mRolling=mData.rolling(time=31, center=True).mean().bfill(dim=\"time\").ffill(dim=\"time\")\n",
    "        sRolling=mData.rolling(time=31, center=True).std().bfill(dim=\"time\").ffill(dim=\"time\")\n",
    "        normData=(mData-mRolling)/sRolling\n",
    "        a.append(normData)\n",
    "    combineArray=xr.concat(a,'time')\n",
    "    outArray=combineArray.sortby('time')\n",
    "    return outArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "consolidated-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open ERA5 Datasets\n",
    "data=xr.open_dataset('ERA5_Input_Exp8.nc')\n",
    "#Load in preprocessed data\n",
    "cres=data.cres_pre\n",
    "netTOAcs=data.netTOAcs_pre\n",
    "crel=data.crel_pre\n",
    "\n",
    "data1=xr.open_dataset('ERA5_Output_PrecipCon.nc')\n",
    "pr=data1.pr\n",
    "\n",
    "lat=cres.lat\n",
    "lon=cres.lon\n",
    "\n",
    "time=cres.time\n",
    "\n",
    "#Try just selecting the indian ocean\n",
    "cres=cres.sel(lon=slice(40,115))\n",
    "crel=crel.sel(lon=slice(40,115))\n",
    "netTOAcs=netTOAcs.sel(lon=slice(40,115))\n",
    "\n",
    "cres=cres.sel(lat=slice(40,-40))\n",
    "crel=crel.sel(lat=slice(40,-40))\n",
    "netTOAcs=netTOAcs.sel(lat=slice(40,-40))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "forward-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Monsoon Months\n",
    "months=[6,7,8,9]\n",
    "leadmonths=[6,7,8,9]\n",
    "\n",
    "#varOut.where(varOut.time.dt.month.isin(months), drop=True) #Change varOut to desired variable\n",
    "prec=pr.sel(time=pr.time.dt.month.isin(months))\n",
    "cresIn=cres.sel(time=cres.time.dt.month.isin(leadmonths))\n",
    "netTOAcsIn=netTOAcs.sel(time=netTOAcs.time.dt.month.isin(leadmonths))\n",
    "crelIn=crel.sel(time=crel.time.dt.month.isin(leadmonths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "precise-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "land=data.lsMask\n",
    "land=land.sel(time=land.time.dt.month.isin(months))\n",
    "\n",
    "land=land.sel(lon=slice(60,100))\n",
    "land=land[:,240:321,:] #for some reason slicing latitude is producing Nans so I select lat manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alert-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only the SAM lat,lon range: 60-100E, 10-30N\n",
    "precip=prec.sel(lon=slice(60,100))\n",
    "precip=precip[:,240:321,:] #Same manual lat selection\n",
    "precip=xr.where(land==0,np.nan,precip) #remove oceans, monsoon is defined as only over land \n",
    "\n",
    "#Do weighted correction on precipitation\n",
    "weights=np.cos(np.deg2rad(precip.lat))\n",
    "prec_index=precip.weighted(weights).mean(dim=('lat','lon'))\n",
    "prec_index=prec_index*60*60*24 #conversion to mm/day, exluding dividing by rho and multiplying by 1000mm/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "consolidated-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove seasonal cycle\n",
    "prec_index=removeSC(prec_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "casual-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize\n",
    "prec_index=calStdNorAnom(prec_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "olympic-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detrend\n",
    "time=prec_index.time\n",
    "prec_index=prec_index.to_numpy()\n",
    "time=time.to_numpy()\n",
    "time=time.astype(int)/10**9\n",
    "\n",
    "prec_index=altdetrend(prec_index,time)\n",
    "prec_index=xr.DataArray(prec_index,coords=[time],dims=['time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "verified-citizenship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 high\n",
      "22 average\n",
      "20 low\n"
     ]
    }
   ],
   "source": [
    "mysd=prec_index.std()\n",
    "mymean=prec_index.mean()\n",
    "\n",
    "#test=pd.cut(prec_index, [mymean - mysd* 10000, mymean - mysd * 2,  mymean - mysd, mymean - 0.5*mysd, mymean + 0.5*mysd, mymean + mysd, mymean + mysd *2, mymean + mysd* 10000])\n",
    "\n",
    "#buckets=pd.Categorical(pd.cut(prec_index, [mymean - mysd* 10000, mymean - mysd * 2,  mymean - mysd, mymean - 0.5*mysd, mymean + 0.5*mysd, mymean + mysd, mymean + mysd *2, mymean + mysd* 10000])).rename_categories(['very very low','very low','low','average','high','very high','very very high'])\n",
    "\n",
    "buckets=pd.Categorical(pd.cut(prec_index, [mymean - mysd* 10000,  mymean - 0.5*mysd,  mymean + 0.5*mysd, mymean + mysd* 10000])).rename_categories(['low','average','high'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(buckets)\n",
    "high=buckets=='high'\n",
    "average=buckets=='average'\n",
    "low=buckets=='low'\n",
    "print(len(np.where(high)[0]),'high')\n",
    "print(len(np.where(average)[0]),'average')\n",
    "print(len(np.where(low)[0]),'low')\n",
    "\n",
    "labelprec=le.transform(buckets)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "#nclasses=7\n",
    "nclasses=3\n",
    "dummy_y=to_categorical(labelprec,nclasses) #converts to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "clinical-import",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 50, 321, 1440, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare Data for CNN\n",
    "\n",
    "# split into train and test\n",
    "cres_train, cres_test, crel_train, crel_test, netTOAcs_train, netTOAcs_test, y_train, y_test = train_test_split(cresIn, crelIn, netTOAcsIn, dummy_y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Add extra dimension to data, required for algorithm\n",
    "crestrain=cres_train.values\n",
    "crestrain=crestrain[:,:,:,None]\n",
    "\n",
    "creltrain=crel_train.values\n",
    "creltrain=creltrain[:,:,:,None]\n",
    "\n",
    "netTOAcstrain=netTOAcs_train.values\n",
    "netTOAcstrain=netTOAcstrain[:,:,:,None]\n",
    "\n",
    "#---------------------------------------------------------\n",
    "crestest=cres_test.values\n",
    "crestest=crestest[:,:,:,None]\n",
    "\n",
    "creltest=crel_test.values\n",
    "creltest=creltest[:,:,:,None]\n",
    "\n",
    "netTOAcstest=netTOAcs_test.values\n",
    "netTOAcstest=netTOAcstest[:,:,:,None]\n",
    "\n",
    "X_test=np.array([crestest,creltest,netTOAcstest])\n",
    "X_train=np.array([crestrain,creltrain,netTOAcstrain])\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "X_train_reshape = np.einsum('lkija->klija',X_train)\n",
    "X_train_reshape.shape\n",
    "\n",
    "X_test_reshape = np.einsum('lkija->klija',X_test)\n",
    "X_test_reshape.shape\n",
    "\n",
    "# check for nan\n",
    "np.isnan(X_test_reshape).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dynamic-melissa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "anticipated-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' #To be compatable with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "turned-victoria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3/3 [==============================] - 9s 1s/step - loss: 34.5621 - accuracy: 0.2889 - val_loss: 13.7479 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/15\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 40.2934 - accuracy: 0.4222 - val_loss: 2.5708 - val_accuracy: 0.8000\n",
      "Epoch 3/15\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 14.6923 - accuracy: 0.3556 - val_loss: 1.4660 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 2.9095 - accuracy: 0.3778 - val_loss: 1.4164 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 1.2975 - accuracy: 0.3778 - val_loss: 1.3721 - val_accuracy: 0.2000\n",
      "Epoch 6/15\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 1.2727 - accuracy: 0.5111 - val_loss: 1.3567 - val_accuracy: 0.2000\n",
      "Epoch 7/15\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 1.3004 - accuracy: 0.3111 - val_loss: 1.3451 - val_accuracy: 0.2000\n",
      "Epoch 8/15\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 1.3126 - accuracy: 0.3111 - val_loss: 1.3352 - val_accuracy: 0.2000\n",
      "Epoch 9/15\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 1.3139 - accuracy: 0.3333 - val_loss: 1.3267 - val_accuracy: 0.6000\n",
      "Epoch 10/15\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 1.3027 - accuracy: 0.4444 - val_loss: 1.3197 - val_accuracy: 0.8000\n",
      "Epoch 11/15\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 1.2967 - accuracy: 0.5556 - val_loss: 1.3132 - val_accuracy: 0.8000\n",
      "Epoch 12/15\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 1.2905 - accuracy: 0.6222 - val_loss: 1.3080 - val_accuracy: 0.8000\n",
      "Epoch 13/15\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 1.2796 - accuracy: 0.6000 - val_loss: 1.3016 - val_accuracy: 0.8000\n",
      "Epoch 14/15\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 1.2550 - accuracy: 0.4444 - val_loss: 1.2955 - val_accuracy: 0.8000\n",
      "Epoch 15/15\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 1.2299 - accuracy: 0.6000 - val_loss: 1.2912 - val_accuracy: 0.8000\n",
      "Score for fold 1: loss of 1.2911673784255981; accuracy of 80.0000011920929%\n",
      "Epoch 1/15\n",
      "3/3 [==============================] - 1s 266ms/step - loss: 58.5278 - accuracy: 0.4000 - val_loss: 8.7921 - val_accuracy: 0.4000\n",
      "Epoch 2/15\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 29.1732 - accuracy: 0.3778 - val_loss: 3.3153 - val_accuracy: 0.4000\n",
      "Epoch 3/15\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 7.0656 - accuracy: 0.4889 - val_loss: 2.3081 - val_accuracy: 0.2000\n",
      "Epoch 4/15\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 4.3869 - accuracy: 0.4000 - val_loss: 1.4489 - val_accuracy: 0.2000\n",
      "Epoch 5/15\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 1.6365 - accuracy: 0.4000 - val_loss: 1.3626 - val_accuracy: 0.4000\n",
      "Epoch 6/15\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 1.1970 - accuracy: 0.6000 - val_loss: 1.3477 - val_accuracy: 0.4000\n",
      "Epoch 7/15\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 1.2727 - accuracy: 0.3111 - val_loss: 1.3380 - val_accuracy: 0.4000\n",
      "Epoch 8/15\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 1.2901 - accuracy: 0.3111 - val_loss: 1.3329 - val_accuracy: 0.4000\n",
      "Epoch 9/15\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 1.2713 - accuracy: 0.3111 - val_loss: 1.3286 - val_accuracy: 0.4000\n",
      "Epoch 10/15\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 1.2638 - accuracy: 0.3556 - val_loss: 1.3243 - val_accuracy: 0.4000\n",
      "Epoch 11/15\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 1.2455 - accuracy: 0.4889 - val_loss: 1.3207 - val_accuracy: 0.4000\n",
      "Epoch 12/15\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 1.2306 - accuracy: 0.6444 - val_loss: 1.3182 - val_accuracy: 0.4000\n",
      "Epoch 13/15\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 1.2188 - accuracy: 0.8889 - val_loss: 1.3163 - val_accuracy: 0.4000\n",
      "Epoch 14/15\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 1.1906 - accuracy: 0.9333 - val_loss: 1.3164 - val_accuracy: 0.4000\n",
      "Epoch 15/15\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 1.1694 - accuracy: 0.9556 - val_loss: 1.3202 - val_accuracy: 0.4000\n",
      "Score for fold 2: loss of 1.320219874382019; accuracy of 40.00000059604645%\n",
      "Epoch 1/15\n",
      "3/3 [==============================] - 1s 266ms/step - loss: 56.7620 - accuracy: 0.2667 - val_loss: 5.8269 - val_accuracy: 0.6000\n",
      "Epoch 2/15\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 28.5814 - accuracy: 0.3556 - val_loss: 2.6764 - val_accuracy: 0.4000\n",
      "Epoch 3/15\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 9.9486 - accuracy: 0.3111 - val_loss: 1.2989 - val_accuracy: 0.6000\n",
      "Epoch 4/15\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 1.5729 - accuracy: 0.5111 - val_loss: 1.3828 - val_accuracy: 0.4000\n",
      "Epoch 5/15\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 1.3046 - accuracy: 0.5556 - val_loss: 1.3855 - val_accuracy: 0.2000\n",
      "Epoch 6/15\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 1.3669 - accuracy: 0.6444 - val_loss: 1.3630 - val_accuracy: 0.2000\n",
      "Epoch 7/15\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 1.3242 - accuracy: 0.6667 - val_loss: 1.3480 - val_accuracy: 0.4000\n",
      "Epoch 8/15\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 1.2849 - accuracy: 0.6444 - val_loss: 1.3396 - val_accuracy: 0.4000\n",
      "Epoch 9/15\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 1.2700 - accuracy: 0.6667 - val_loss: 1.3335 - val_accuracy: 0.4000\n",
      "Epoch 10/15\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 1.2576 - accuracy: 0.6444 - val_loss: 1.3273 - val_accuracy: 0.4000\n",
      "Epoch 11/15\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 1.2459 - accuracy: 0.6889 - val_loss: 1.3203 - val_accuracy: 0.4000\n",
      "Epoch 12/15\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 1.2290 - accuracy: 0.6222 - val_loss: 1.3132 - val_accuracy: 0.4000\n",
      "Epoch 13/15\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 1.2137 - accuracy: 0.6667 - val_loss: 1.3061 - val_accuracy: 0.4000\n",
      "Epoch 14/15\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 1.1781 - accuracy: 0.6444 - val_loss: 1.2959 - val_accuracy: 0.4000\n",
      "Epoch 15/15\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 1.1297 - accuracy: 0.6444 - val_loss: 1.2847 - val_accuracy: 0.6000\n",
      "Score for fold 3: loss of 1.284745216369629; accuracy of 60.00000238418579%\n",
      "Epoch 1/15\n",
      "3/3 [==============================] - 1s 265ms/step - loss: 31.1756 - accuracy: 0.4667 - val_loss: 16.2196 - val_accuracy: 0.2000\n",
      "Epoch 2/15\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 60.9078 - accuracy: 0.3333 - val_loss: 1.1799 - val_accuracy: 0.8000\n",
      "Epoch 3/15\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 15.8221 - accuracy: 0.2667 - val_loss: 1.4127 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 3.0142 - accuracy: 0.5111 - val_loss: 1.5694 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 1.9999 - accuracy: 0.4222 - val_loss: 1.5206 - val_accuracy: 0.2000\n",
      "Epoch 6/15\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 1.3542 - accuracy: 0.5556 - val_loss: 1.4649 - val_accuracy: 0.2000\n",
      "Epoch 7/15\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 1.3756 - accuracy: 0.3111 - val_loss: 1.4015 - val_accuracy: 0.2000\n",
      "Epoch 8/15\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 1.3271 - accuracy: 0.3111 - val_loss: 1.3655 - val_accuracy: 0.2000\n",
      "Epoch 9/15\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 1.2957 - accuracy: 0.3111 - val_loss: 1.3460 - val_accuracy: 0.2000\n",
      "Epoch 10/15\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 1.2817 - accuracy: 0.3333 - val_loss: 1.3352 - val_accuracy: 0.2000\n",
      "Epoch 11/15\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 1.2680 - accuracy: 0.4889 - val_loss: 1.3277 - val_accuracy: 0.2000\n",
      "Epoch 12/15\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 1.2609 - accuracy: 0.6667 - val_loss: 1.3223 - val_accuracy: 0.2000\n",
      "Epoch 13/15\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 1.2393 - accuracy: 0.7333 - val_loss: 1.3192 - val_accuracy: 0.2000\n",
      "Epoch 14/15\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 1.2268 - accuracy: 0.7778 - val_loss: 1.3179 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/15\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 1.2123 - accuracy: 0.6444 - val_loss: 1.3182 - val_accuracy: 0.0000e+00\n",
      "Score for fold 4: loss of 1.3182491064071655; accuracy of 0.0%\n",
      "Epoch 1/15\n",
      "3/3 [==============================] - 1s 265ms/step - loss: 70.6814 - accuracy: 0.2889 - val_loss: 3.6782 - val_accuracy: 0.4000\n",
      "Epoch 2/15\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 18.8951 - accuracy: 0.3333 - val_loss: 1.8397 - val_accuracy: 0.4000\n",
      "Epoch 3/15\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 8.3984 - accuracy: 0.5333 - val_loss: 1.3496 - val_accuracy: 0.2000\n",
      "Epoch 4/15\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 2.4978 - accuracy: 0.5333 - val_loss: 1.3865 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 1.1914 - accuracy: 0.5111 - val_loss: 1.3767 - val_accuracy: 0.2000\n",
      "Epoch 6/15\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 1.2936 - accuracy: 0.4000 - val_loss: 1.3568 - val_accuracy: 0.2000\n",
      "Epoch 7/15\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 1.2811 - accuracy: 0.4000 - val_loss: 1.3424 - val_accuracy: 0.2000\n",
      "Epoch 8/15\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 1.2526 - accuracy: 0.4000 - val_loss: 1.3331 - val_accuracy: 0.2000\n",
      "Epoch 9/15\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 1.2383 - accuracy: 0.4000 - val_loss: 1.3258 - val_accuracy: 0.2000\n",
      "Epoch 10/15\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 1.2319 - accuracy: 0.4000 - val_loss: 1.3198 - val_accuracy: 0.2000\n",
      "Epoch 11/15\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 1.2325 - accuracy: 0.4000 - val_loss: 1.3147 - val_accuracy: 0.2000\n",
      "Epoch 12/15\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 1.2260 - accuracy: 0.4000 - val_loss: 1.3104 - val_accuracy: 0.2000\n",
      "Epoch 13/15\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 1.2114 - accuracy: 0.4000 - val_loss: 1.3068 - val_accuracy: 0.2000\n",
      "Epoch 14/15\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 1.2022 - accuracy: 0.4222 - val_loss: 1.3041 - val_accuracy: 0.2000\n",
      "Epoch 15/15\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 1.1785 - accuracy: 0.4444 - val_loss: 1.3024 - val_accuracy: 0.2000\n",
      "Score for fold 5: loss of 1.3024009466171265; accuracy of 20.000000298023224%\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3552, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_951999/1178505133.py\", line 50, in <module>\n",
      "    validation_data=(X_train_reshape[test],y_train[test]))\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/keras/engine/training.py\", line 1384, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 915, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 980, in _call\n",
      "    return self._stateless_fn(*args, **kwds)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2957, in __call__\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1854, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 504, in call\n",
      "    ctx=ctx)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 55, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2098, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3552, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_951999/1178505133.py\", line 50, in <module>\n",
      "    validation_data=(X_train_reshape[test],y_train[test]))\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/keras/engine/training.py\", line 1384, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 915, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 980, in _call\n",
      "    return self._stateless_fn(*args, **kwds)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2957, in __call__\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1854, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 504, in call\n",
      "    ctx=ctx)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 55, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2098, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3472, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3569, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2098, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/kgemmell/miniconda3/envs/test_gpu/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_951999/1178505133.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n\u001b[0;32m---> 50\u001b[0;31m                          validation_data=(X_train_reshape[test],y_train[test]))\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2097\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3471\u001b[0m                         \u001b[0masy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3472\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0masync_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3473\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2100\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2101\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2097\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TypeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[0;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[0m\n\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001b[0;32m-> 3257\u001b[0;31m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001b[0m\u001b[1;32m   3258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3259\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_execution_succeeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_raised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3490\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_before_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3491\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3492\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2101\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001b[0;32m-> 1143\u001b[0;31m                                                                      chained_exceptions_tb_offset)\n\u001b[0m\u001b[1;32m   1144\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    \n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu', padding='same',  kernel_regularizer=regularizers.l2(l=0.01),\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same',  kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same',  kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    \n",
    "\n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(512, activation='relu'))\n",
    "    #cnn3.add(Dropout(rate = 0.2))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.001) # learning_rate\n",
    "    #sgd=keras.optimizers.SGD(lr=0.0001)\n",
    "    #adadelta=keras.optimizers.Adadelta(learning_rate=0.001)\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=15 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test],y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cnn3.predict((X_train_reshape), batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.argmax ( pred , axis=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted)\n",
    "y_true=np.argmax (y_train , axis=-1 )\n",
    "print(y_true)\n",
    "\n",
    "cnt=0\n",
    "for i,p in enumerate(predicted):\n",
    "    if (p==y_true[i]):\n",
    "        cnt=cnt+1\n",
    "\n",
    "#print(cnt, 'out of 201')\n",
    "print(cnt, 'out of 50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = cnn3.predict(X_test_reshape, batch_size=10)\n",
    "ytestPred=np.argmax ( pred_test , axis=-1 )\n",
    "ytruePred=np.argmax ( y_test , axis=-1 )\n",
    "print(ytestPred)\n",
    "print(ytruePred)\n",
    "\n",
    "cnt=0\n",
    "for i,p in enumerate(ytestPred):\n",
    "    if (p==ytruePred[i]):\n",
    "        cnt=cnt+1\n",
    "\n",
    "#print(cnt,'out of 51')\n",
    "print(cnt,'out of 13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the confusion matrix\n",
    "#print(metrics.confusion_matrix(ytestPred,ytruePred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(ytestPred,ytruePred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['accuracy'], label='train')\n",
    "plt.plot(hist.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-maldives",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-graphic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-quantum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-generation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-cambridge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-portrait",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-heavy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-speech",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-table",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-catering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-receptor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-viewer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-creature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "stopped-semiconductor",
   "metadata": {},
   "source": [
    "# Models 1,2,3 (change epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "        \n",
    "# Define 10-fold cross validation test harness\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(8, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=10 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "        \n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=10, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-baghdad",
   "metadata": {},
   "source": [
    "# Model 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "        \n",
    "# Define 10-fold cross validation test harness\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(8, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=10 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "        \n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=10, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-behavior",
   "metadata": {},
   "source": [
    "# Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "        \n",
    "# Define 10-fold cross validation test harness\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=5, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(8, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=10 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "        \n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=10, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-paper",
   "metadata": {},
   "source": [
    "\n",
    "# Model 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=5, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    #cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(8, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=10 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-antenna",
   "metadata": {},
   "source": [
    "# Model 7, 8 , 9 (change epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "    \n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    cnn3.add(Dense(16, activation='relu', kernel_regularizer='l2'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    cnn3.add(Dense(8, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=10 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs,batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-launch",
   "metadata": {},
   "source": [
    "# Model 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-black",
   "metadata": {},
   "source": [
    "# Model 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "    \n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    cnn3.add(Dense(8, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=20 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-sydney",
   "metadata": {},
   "source": [
    "# Model 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "    \n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    cnn3.add(Dense(8, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=5 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-vector",
   "metadata": {},
   "source": [
    "# Model 13, 14, 15, 16, 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "    \n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    cnn3.add(Dense(512, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=20 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=30, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-approval",
   "metadata": {},
   "source": [
    "# Model 18, 19 (change dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "    \n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    cnn3.add(Dense(128, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=20 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-ocean",
   "metadata": {},
   "source": [
    "# Model 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "    \n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(128, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    cnn3.add(Dense(512, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=20 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-trigger",
   "metadata": {},
   "source": [
    "# Model 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "    \n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    cnn3.add(Dense(1024, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=20 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-favor",
   "metadata": {},
   "source": [
    "# Model 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "    \n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    cnn3.add(Dense(256, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=20 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-comment",
   "metadata": {},
   "source": [
    "# Model 23, 24, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "    \n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.2))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.3))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(128, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.4))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=20 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=10, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-browse",
   "metadata": {},
   "source": [
    "# Model 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "    \n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    cnn3.add(Dense(256, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=20 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-transsexual",
   "metadata": {},
   "source": [
    "# Different Optimizers/ Kernel Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu', padding='same',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                    bias_regularizer=regularizers.l2(1e-4),\n",
    "                    activity_regularizer=regularizers.l2(1e-5),\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    #cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    #cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    #cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    #cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    #cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    #cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    cnn3.add(Dense(16, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.001) # learning_rate\n",
    "    sgd=keras.optimizers.SGD(lr=0.0001)\n",
    "    adadelta=keras.optimizers.Adadelta(learning_rate=0.001)\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=20 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=10, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-baker",
   "metadata": {},
   "source": [
    "# Models 28 - 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    \n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l=0.01),\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same', kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(128, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #sgd=keras.optimizers.SGD(lr=0.0001)\n",
    "    #adadelta=keras.optimizers.Adadelta(learning_rate=0.001)\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=20 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test],y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-spank",
   "metadata": {},
   "source": [
    "# Model 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    \n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l=0.01),\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.2))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same', kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.2))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same', kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.2))\n",
    "    \n",
    "    cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same', kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.2))\n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(512, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "    cnn3.add(Dropout(rate = 0.4))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #sgd=keras.optimizers.SGD(lr=0.0001)\n",
    "    #adadelta=keras.optimizers.Adadelta(learning_rate=0.001)\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=20 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test],y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-caribbean",
   "metadata": {},
   "source": [
    "# Model 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    \n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu', padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(64, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.2))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #sgd=keras.optimizers.SGD(lr=0.0001)\n",
    "    #adadelta=keras.optimizers.Adadelta(learning_rate=0.001)\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=50 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test],y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-weather",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-project",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-permission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-wellington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-recording",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-zambia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-punch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-filling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-worry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-church",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-climate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-assets",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-analysis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_gpu",
   "language": "python",
   "name": "test_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
