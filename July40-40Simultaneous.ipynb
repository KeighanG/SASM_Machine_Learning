{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hungry-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import gc\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import dask\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import s3fs\n",
    "import zarr\n",
    "import geocat.comp\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from math import e\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv3D, Flatten,MaxPooling3D,AveragePooling3D, concatenate,Input ,SpatialDropout3D,Dropout\n",
    "from sklearn import metrics\n",
    "from keras import backend as K\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.constraints import unit_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "french-claim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: /physical_device:GPU:0   Type: GPU\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)\n",
    "    \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "optional-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing functions\n",
    "#3D detrend function\n",
    "def detrend(x:np.ndarray,time:np.ndarray):\n",
    "        nt,nx,ny = x.shape\n",
    "        xtemp = x.reshape(nt,nx*ny)\n",
    "        p = np.polyfit(time, xtemp, deg=3)\n",
    "        fit = p[0]*(time[:,np.newaxis] **3)+ p[1]*(time[:,np.newaxis]**2) + p[2]*(time[:,np.newaxis]) + p[3]\n",
    "        return x - fit.reshape(nt,nx,ny)\n",
    "    \n",
    "#1D detrend function\n",
    "def altdetrend(x:np.ndarray,time:np.ndarray):\n",
    "        nt = x.shape\n",
    "        xtemp = x.reshape(nt)\n",
    "        p = np.polyfit(time, x, deg=1)\n",
    "        fit = p[0]*(time[:,np.newaxis])+ p[1]\n",
    "        return x - fit.reshape(nt)\n",
    "    \n",
    "def remove_time_mean(x):\n",
    "        return x - x.mean(dim='time')\n",
    "\n",
    "def removeSC(x):\n",
    "        return x.groupby('time.month').apply(remove_time_mean)\n",
    "\n",
    "# Calculate std normal anomaly\n",
    "def calStdNorAnom(x):\n",
    "    a=[]\n",
    "    for m in np.unique(x.time.dt.month):\n",
    "        mData=x[x.time.dt.month==m]\n",
    "        mRolling=mData.rolling(time=31, center=True).mean().bfill(dim=\"time\").ffill(dim=\"time\")\n",
    "        sRolling=mData.rolling(time=31, center=True).std().bfill(dim=\"time\").ffill(dim=\"time\")\n",
    "        normData=(mData-mRolling)/sRolling\n",
    "        a.append(normData)\n",
    "    combineArray=xr.concat(a,'time')\n",
    "    outArray=combineArray.sortby('time')\n",
    "    return outArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "arranged-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to AWS S3 storage\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "## By downloading the master CSV file enumerating all available data stores, we can interact with the spreadsheet\n",
    "## through a pandas DataFrame to search and explore for relevant data using the CMIP6 controlled vocabulary:\n",
    "df = pd.read_csv(\"https://cmip6-pds.s3.amazonaws.com/pangeo-cmip6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "requested-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(qstring):\n",
    "    df_subset = df.query(qstring)\n",
    "    if df_subset.empty:\n",
    "        print('data not available for '+qstring)\n",
    "    else:\n",
    "        for v in df_subset.zstore.values:\n",
    "            zstore = v\n",
    "            mapper = fs.get_mapper(zstore)\n",
    "            return_ds = xr.open_zarr(mapper, consolidated=True)\n",
    "    return(return_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spatial-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open CESM2 Ensemble Datasets\n",
    "modelName=\"'CESM2'\"\n",
    "institute=\"'NCAR'\"\n",
    "expList=[\"'historical'\"]\n",
    "actList=[\"'CMIP'\"]\n",
    "membList=[\"'r1i1p1f1'\", \"'r2i1p1f1'\", \"'r3i1p1f1'\", \"'r4i1p1f1'\" , \"'r5i1p1f1'\", \"'r6i1p1f1'\", \"'r7i1p1f1'\",\"'r8i1p1f1'\",\"'r9i1p1f1'\",\"'r10i1p1f1'\",\"'r11i1p1f1'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "decimal-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "creslist=[]\n",
    "crellist=[]\n",
    "netTOAcslist=[]\n",
    "dummy_ylist=[]\n",
    "\n",
    "for j,memb in enumerate(membList):\n",
    "        inputStr  = \"institution_id =='NCAR' & source_id=='CESM2' & table_id=='Amon' & experiment_id=='historical' &  member_id==\"+memb+\" & variable_id==\"\n",
    "        altinputStr  = \"activity_id=='CMIP' & table_id=='fx' & source_id=='CESM2' & experiment_id=='historical' &  member_id==\"+memb+\" & variable_id==\"\n",
    "        rsut_ds   = getData(inputStr+\"'rsut'\")\n",
    "        pr_ds     = getData(inputStr+\"'pr'\")\n",
    "        rsutcs_ds = getData(inputStr+\"'rsutcs'\")\n",
    "        sftlf_ds = getData(altinputStr+\"'sftlf'\")\n",
    "        rlut_ds   =getData(inputStr+\"'rlut'\")\n",
    "        rlutcs_ds  =getData(inputStr+\"'rlutcs'\")\n",
    "        rsdt_ds  =getData(inputStr+\"'rsdt'\")\n",
    "        \n",
    "        netTOAcs = rsdt_ds.rsdt - rsutcs_ds.rsutcs - rlutcs_ds.rlutcs\n",
    "        \n",
    "        cres= rsutcs_ds.rsutcs-rsut_ds.rsut\n",
    "        crel=rlutcs_ds.rlutcs-rlut_ds.rlut\n",
    "        prec=pr_ds.pr\n",
    "        land=sftlf_ds.sftlf\n",
    "    \n",
    "        datetimeindex=cres.indexes['time'].to_datetimeindex()\n",
    "        cres['time']=datetimeindex\n",
    "        crel['time']=datetimeindex\n",
    "        netTOAcs['time']=datetimeindex\n",
    "        prec['time']=datetimeindex\n",
    "        \n",
    "        cres,land= xr.broadcast(cres,land) #add time dimension to land variable for compatability with CRE variables\n",
    "        \n",
    "        #Try just selecting the indian ocean\n",
    "        #cres=cres.sel(lat=slice(-40,10))\n",
    "        #crel=crel.sel(lat=slice(-40,10))\n",
    "        #netTOAcs=netTOAcs.sel(lat=slice(-40,10))\n",
    "\n",
    "        #cres=cres.sel(lon=slice(40,115))\n",
    "        #crel=crel.sel(lon=slice(40,115))\n",
    "        #netTOAcs=netTOAcs.sel(lon=slice(40,115))\n",
    "        \n",
    "        cres=cres.sel(lat=slice(-40,40))\n",
    "        crel=crel.sel(lat=slice(-40,40))\n",
    "        netTOAcs=netTOAcs.sel(lat=slice(-40,40))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #months=[2,3,4,5]\n",
    "        #leadmonths=[6,7,8,9]\n",
    "        months=[7]\n",
    "        leadmonths=[7]\n",
    "\n",
    "        #varOut.where(varOut.time.dt.month.isin(months), drop=True) #Change varOut to desired variable\n",
    "        prec=prec.sel(time=prec.time.dt.month.isin(months))\n",
    "        cres=cres.sel(time=cres.time.dt.month.isin(leadmonths))\n",
    "        crel=crel.sel(time=crel.time.dt.month.isin(leadmonths))\n",
    "        netTOAcs=netTOAcs.sel(time=netTOAcs.time.dt.month.isin(leadmonths))\n",
    "        land=land.sel(time=land.time.dt.month.isin(months))\n",
    "        \n",
    "        #Select only the SAM lat,lon range: 60-100E, 10-30N\n",
    "        precip=prec.sel(lon=slice(60,100),lat=slice(10,30))\n",
    "        land=land.sel(lon=slice(60,100),lat=slice(10,30))\n",
    "        \n",
    "        precip=xr.where(land==0,np.nan,precip) #remove oceans, monsoon is defined as only over land \n",
    "        \n",
    "        #Do weighted correction on precipitation\n",
    "        weights=np.cos(np.deg2rad(precip.lat))\n",
    "        prec_index=precip.weighted(weights).mean(dim=('lat','lon'))\n",
    "        prec_index=prec_index*60*60*24 #conversion to mm/day, exluding dividing by rho and multiplying by 1000mm/m\n",
    "        \n",
    "        lat=cres.lat\n",
    "        lon=cres.lon\n",
    "        \n",
    "        #Do the preprocessing\n",
    "        cres=removeSC(cres)\n",
    "        cres=calStdNorAnom(cres)\n",
    "        \n",
    "        crel=removeSC(crel)\n",
    "        crel=calStdNorAnom(crel)\n",
    "        \n",
    "        netTOAcs=removeSC(netTOAcs)\n",
    "        netTOAcs=calStdNorAnom(netTOAcs)\n",
    "        \n",
    "        #Detrend\n",
    "        time=cres.time\n",
    "        cres=cres.to_numpy()\n",
    "        crel=crel.to_numpy()\n",
    "        netTOAcs=netTOAcs.to_numpy()\n",
    "        time=time.to_numpy()\n",
    "        time=time.astype(int)/10**9\n",
    "        \n",
    "        cres=detrend(cres,time)\n",
    "        cres=xr.DataArray(cres,coords=[time,lat,lon],dims=['time','lat','lon'])\n",
    "        \n",
    "        crel=detrend(crel,time)\n",
    "        crel=xr.DataArray(crel,coords=[time,lat,lon],dims=['time','lat','lon'])\n",
    "        \n",
    "        netTOAcs=detrend(netTOAcs,time)\n",
    "        netTOAcs=xr.DataArray(netTOAcs,coords=[time,lat,lon],dims=['time','lat','lon'])\n",
    "        \n",
    "        #Precip preprocessing\n",
    "        #Remove seasonal cycle\n",
    "        prec_index=removeSC(prec_index)\n",
    "        \n",
    "        #Normalize\n",
    "        prec_index=calStdNorAnom(prec_index)\n",
    "        \n",
    "        #Detrend\n",
    "        time=prec_index.time\n",
    "        prec_index=prec_index.to_numpy()\n",
    "        time=time.to_numpy()\n",
    "        time=time.astype(int)/10**9\n",
    "        \n",
    "        prec_index=altdetrend(prec_index,time)\n",
    "        prec_index=xr.DataArray(prec_index,coords=[time],dims=['time'])\n",
    "        \n",
    "        mysd=prec_index.std()\n",
    "        mymean=prec_index.mean()\n",
    "\n",
    "        buckets=pd.Categorical(pd.cut(prec_index, [mymean - mysd* 10000,  mymean - 0.5*mysd,  mymean + 0.5*mysd, mymean + mysd* 10000])).rename_categories(['low','average','high'])\n",
    "\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(buckets)\n",
    "\n",
    "        labelprec=le.transform(buckets)\n",
    "\n",
    "        # convert integers to dummy variables (i.e. one hot encoded)\n",
    "        nclasses=3\n",
    "        dummy_y=to_categorical(labelprec,nclasses) #converts to binary\n",
    "        \n",
    "        creslist.append(cres)\n",
    "        cresstack=np.stack(creslist,axis=0)\n",
    "        \n",
    "        crellist.append(crel)\n",
    "        crelstack=np.stack(crellist,axis=0)\n",
    "        \n",
    "        netTOAcslist.append(netTOAcs)\n",
    "        netTOAcsstack=np.stack(netTOAcslist,axis=0)\n",
    "        \n",
    "        dummy_ylist.append(dummy_y)\n",
    "        dummy_ystack=np.stack(dummy_ylist,axis=0)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "magnetic-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate each cres array\n",
    "cresIn1=cresstack[0,:,:,:]\n",
    "cresIn2=cresstack[1,:,:,:]\n",
    "cresIn3=cresstack[2,:,:,:]\n",
    "cresIn4=cresstack[3,:,:,:]\n",
    "cresIn5=cresstack[4,:,:,:]\n",
    "cresIn6=cresstack[5,:,:,:]\n",
    "cresIn7=cresstack[6,:,:,:]\n",
    "cresIn8=cresstack[7,:,:,:]\n",
    "cresIn9=cresstack[8,:,:,:]\n",
    "cresIn10=cresstack[9,:,:,:]\n",
    "cresIn11=cresstack[10,:,:,:]\n",
    "\n",
    "\n",
    "#Concatenate the ensemble members along time axis\n",
    "cresIn=np.concatenate((cresIn1,cresIn2,cresIn3,cresIn4,cresIn5,cresIn6,cresIn7,cresIn8,cresIn9,cresIn10,cresIn11),axis=0)\n",
    "\n",
    "#Seperate each crel array\n",
    "crelIn1=crelstack[0,:,:,:]\n",
    "crelIn2=crelstack[1,:,:,:]\n",
    "crelIn3=crelstack[2,:,:,:]\n",
    "crelIn4=crelstack[3,:,:,:]\n",
    "crelIn5=crelstack[4,:,:,:]\n",
    "crelIn6=crelstack[5,:,:,:]\n",
    "crelIn7=crelstack[6,:,:,:]\n",
    "crelIn8=crelstack[7,:,:,:]\n",
    "crelIn9=crelstack[8,:,:,:]\n",
    "crelIn10=crelstack[9,:,:,:]\n",
    "crelIn11=crelstack[10,:,:,:]\n",
    "\n",
    "#Concatenate the ensemble members along time axis\n",
    "crelIn=np.concatenate((crelIn1,crelIn2,crelIn3,crelIn4,crelIn5,crelIn6,crelIn7,crelIn8,crelIn9,crelIn10,crelIn11),axis=0)\n",
    "\n",
    "#Seperate each netTOAcs array\n",
    "netTOAcsIn1=netTOAcsstack[0,:,:,:]\n",
    "netTOAcsIn2=netTOAcsstack[1,:,:,:]\n",
    "netTOAcsIn3=netTOAcsstack[2,:,:,:]\n",
    "netTOAcsIn4=netTOAcsstack[3,:,:,:]\n",
    "netTOAcsIn5=netTOAcsstack[4,:,:,:]\n",
    "netTOAcsIn6=netTOAcsstack[5,:,:,:]\n",
    "netTOAcsIn7=netTOAcsstack[6,:,:,:]\n",
    "netTOAcsIn8=netTOAcsstack[7,:,:,:]\n",
    "netTOAcsIn9=netTOAcsstack[8,:,:,:]\n",
    "netTOAcsIn10=netTOAcsstack[9,:,:,:]\n",
    "netTOAcsIn11=netTOAcsstack[10,:,:,:]\n",
    "\n",
    "#Concatenate the ensemble members along time axis\n",
    "netTOAcsIn=np.concatenate((netTOAcsIn1,netTOAcsIn2,netTOAcsIn3,netTOAcsIn4,netTOAcsIn5,netTOAcsIn6,netTOAcsIn7,netTOAcsIn8,netTOAcsIn9,netTOAcsIn10,netTOAcsIn11),axis=0)\n",
    "\n",
    "#Seperate each precip_index array\n",
    "yIn1=dummy_ystack[0,:,:]\n",
    "yIn2=dummy_ystack[1,:,:]\n",
    "yIn3=dummy_ystack[2,:,:]\n",
    "yIn4=dummy_ystack[3,:,:]\n",
    "yIn5=dummy_ystack[4,:,:]\n",
    "yIn6=dummy_ystack[5,:,:]\n",
    "yIn7=dummy_ystack[6,:,:]\n",
    "yIn8=dummy_ystack[7,:,:]\n",
    "yIn9=dummy_ystack[8,:,:]\n",
    "yIn10=dummy_ystack[9,:,:]\n",
    "yIn11=dummy_ystack[10,:,:]\n",
    "\n",
    "#Concatenate the ensemble members along time axis\n",
    "yIn=np.concatenate((yIn1,yIn2,yIn3,yIn4,yIn5,yIn6,yIn7,yIn8,yIn9,yIn10,yIn11),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "mechanical-cause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1452, 84, 288, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare Data for CNN\n",
    "cres_train, cres_test, crel_train, crel_test, netTOAcs_train, netTOAcs_test, y_train, y_test = train_test_split(cresIn, crelIn, netTOAcsIn, yIn, stratify=yIn, test_size=0.2, random_state=42)\n",
    "\n",
    "#Add extra dimension to data, required for algorithm\n",
    "crestrain=cres_train[:,:,:,None]\n",
    "creltrain=crel_train[:,:,:,None]\n",
    "netTOAcstrain=netTOAcs_train[:,:,:,None]\n",
    "\n",
    "#---------------------------------------------------------\n",
    "crestest=cres_test[:,:,:,None]\n",
    "creltest=crel_test[:,:,:,None]\n",
    "netTOAcstest=netTOAcs_test[:,:,:,None]\n",
    "\n",
    "X_test=np.array([crestest,creltest,netTOAcstest])\n",
    "X_train=np.array([crestrain,creltrain,netTOAcstrain])\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "X_train_reshape = np.einsum('lkija->klija',X_train)\n",
    "X_train_reshape.shape\n",
    "\n",
    "X_test_reshape = np.einsum('lkija->klija',X_test)\n",
    "X_test_reshape.shape\n",
    "\n",
    "# check for nan\n",
    "np.isnan(X_test_reshape).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "diverse-classic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1452, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "referenced-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' #To be compatable with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "incorporated-linux",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 5s 210ms/step - loss: 1.2341 - accuracy: 0.3285 - val_loss: 1.1059 - val_accuracy: 0.3836\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 1.1762 - accuracy: 0.3599 - val_loss: 1.1060 - val_accuracy: 0.3904\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 1.1361 - accuracy: 0.3913 - val_loss: 1.1061 - val_accuracy: 0.3767\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 2s 119ms/step - loss: 1.1060 - accuracy: 0.4211 - val_loss: 1.1063 - val_accuracy: 0.3767\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 121ms/step - loss: 1.0794 - accuracy: 0.4449 - val_loss: 1.1064 - val_accuracy: 0.3767\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 1.0577 - accuracy: 0.4709 - val_loss: 1.1066 - val_accuracy: 0.3082\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 1.0363 - accuracy: 0.4885 - val_loss: 1.1069 - val_accuracy: 0.3219\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 2s 119ms/step - loss: 1.0152 - accuracy: 0.5107 - val_loss: 1.1070 - val_accuracy: 0.3151\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 1.0003 - accuracy: 0.5161 - val_loss: 1.1072 - val_accuracy: 0.3082\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 119ms/step - loss: 0.9819 - accuracy: 0.5429 - val_loss: 1.1073 - val_accuracy: 0.3082\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 119ms/step - loss: 0.9674 - accuracy: 0.5559 - val_loss: 1.1073 - val_accuracy: 0.3082\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 0.9520 - accuracy: 0.5712 - val_loss: 1.1072 - val_accuracy: 0.3082\n",
      "Epoch 12: early stopping\n",
      "Score for fold 1: loss of 1.1071817874908447; accuracy of 30.821916460990906%\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 3s 133ms/step - loss: 1.3679 - accuracy: 0.3124 - val_loss: 1.1094 - val_accuracy: 0.2466\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 1.2467 - accuracy: 0.3652 - val_loss: 1.1134 - val_accuracy: 0.2466\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 2s 109ms/step - loss: 1.1605 - accuracy: 0.4051 - val_loss: 1.1175 - val_accuracy: 0.2466\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 2s 119ms/step - loss: 1.0966 - accuracy: 0.4387 - val_loss: 1.1218 - val_accuracy: 0.2466\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 119ms/step - loss: 1.0496 - accuracy: 0.4655 - val_loss: 1.1261 - val_accuracy: 0.2466\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 1.0107 - accuracy: 0.4916 - val_loss: 1.1302 - val_accuracy: 0.2466\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 0.9770 - accuracy: 0.5145 - val_loss: 1.1341 - val_accuracy: 0.2466\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 2s 126ms/step - loss: 0.9516 - accuracy: 0.5322 - val_loss: 1.1379 - val_accuracy: 0.2466\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 0.9287 - accuracy: 0.5459 - val_loss: 1.1418 - val_accuracy: 0.2466\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 122ms/step - loss: 0.9092 - accuracy: 0.5651 - val_loss: 1.1466 - val_accuracy: 0.2466\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 0.8899 - accuracy: 0.5750 - val_loss: 1.1509 - val_accuracy: 0.2466\n",
      "Epoch 11: early stopping\n",
      "Score for fold 2: loss of 1.1508903503417969; accuracy of 24.657534062862396%\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 3s 209ms/step - loss: 1.2131 - accuracy: 0.3328 - val_loss: 1.1071 - val_accuracy: 0.2690\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 124ms/step - loss: 1.1371 - accuracy: 0.3826 - val_loss: 1.1087 - val_accuracy: 0.2690\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 2s 123ms/step - loss: 1.0830 - accuracy: 0.4277 - val_loss: 1.1105 - val_accuracy: 0.2690\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 2s 122ms/step - loss: 1.0412 - accuracy: 0.4629 - val_loss: 1.1124 - val_accuracy: 0.2690\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 123ms/step - loss: 1.0089 - accuracy: 0.4943 - val_loss: 1.1142 - val_accuracy: 0.2690\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 2s 123ms/step - loss: 0.9822 - accuracy: 0.5203 - val_loss: 1.1164 - val_accuracy: 0.2690\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.9575 - accuracy: 0.5417 - val_loss: 1.1194 - val_accuracy: 0.2690\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.9342 - accuracy: 0.5547 - val_loss: 1.1218 - val_accuracy: 0.2690\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 109ms/step - loss: 0.9158 - accuracy: 0.5685 - val_loss: 1.1246 - val_accuracy: 0.2690\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 121ms/step - loss: 0.8944 - accuracy: 0.5830 - val_loss: 1.1273 - val_accuracy: 0.2690\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 122ms/step - loss: 0.8768 - accuracy: 0.5937 - val_loss: 1.1296 - val_accuracy: 0.2690\n",
      "Epoch 11: early stopping\n",
      "Score for fold 3: loss of 1.1295971870422363; accuracy of 26.896551251411438%\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 100ms/step - loss: 1.2144 - accuracy: 0.3259 - val_loss: 1.1065 - val_accuracy: 0.2828\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 1.1081 - accuracy: 0.3894 - val_loss: 1.1065 - val_accuracy: 0.2828\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 1.0467 - accuracy: 0.4353 - val_loss: 1.1066 - val_accuracy: 0.2828\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 1.0036 - accuracy: 0.4744 - val_loss: 1.1069 - val_accuracy: 0.2828\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.9661 - accuracy: 0.5027 - val_loss: 1.1071 - val_accuracy: 0.2828\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9372 - accuracy: 0.5256 - val_loss: 1.1068 - val_accuracy: 0.2828\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.9105 - accuracy: 0.5463 - val_loss: 1.1064 - val_accuracy: 0.2828\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.8884 - accuracy: 0.5532 - val_loss: 1.1052 - val_accuracy: 0.2828\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.8656 - accuracy: 0.5800 - val_loss: 1.1039 - val_accuracy: 0.2828\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.8462 - accuracy: 0.5968 - val_loss: 1.1018 - val_accuracy: 0.2828\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.8271 - accuracy: 0.6121 - val_loss: 1.0999 - val_accuracy: 0.2897\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.8109 - accuracy: 0.6266 - val_loss: 1.0979 - val_accuracy: 0.2828\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7954 - accuracy: 0.6450 - val_loss: 1.0955 - val_accuracy: 0.2828\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7814 - accuracy: 0.6496 - val_loss: 1.0922 - val_accuracy: 0.2828\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7673 - accuracy: 0.6603 - val_loss: 1.0885 - val_accuracy: 0.2897\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.7538 - accuracy: 0.6710 - val_loss: 1.0842 - val_accuracy: 0.2966\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.7414 - accuracy: 0.6817 - val_loss: 1.0776 - val_accuracy: 0.3172\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.7290 - accuracy: 0.6832 - val_loss: 1.0700 - val_accuracy: 0.3241\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.7159 - accuracy: 0.6963 - val_loss: 1.0601 - val_accuracy: 0.3310\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.7068 - accuracy: 0.7047 - val_loss: 1.0484 - val_accuracy: 0.3448\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.6970 - accuracy: 0.7039 - val_loss: 1.0350 - val_accuracy: 0.3586\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.6870 - accuracy: 0.7054 - val_loss: 1.0210 - val_accuracy: 0.3655\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.6763 - accuracy: 0.7093 - val_loss: 1.0070 - val_accuracy: 0.3931\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.6672 - accuracy: 0.7261 - val_loss: 0.9925 - val_accuracy: 0.4414\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.6561 - accuracy: 0.7284 - val_loss: 0.9800 - val_accuracy: 0.4621\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.6470 - accuracy: 0.7445 - val_loss: 0.9649 - val_accuracy: 0.5034\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.6379 - accuracy: 0.7467 - val_loss: 0.9491 - val_accuracy: 0.5241\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.6294 - accuracy: 0.7460 - val_loss: 0.9344 - val_accuracy: 0.5379\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.6207 - accuracy: 0.7613 - val_loss: 0.9187 - val_accuracy: 0.5586\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.6112 - accuracy: 0.7628 - val_loss: 0.9070 - val_accuracy: 0.5655\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.6047 - accuracy: 0.7689 - val_loss: 0.8930 - val_accuracy: 0.5862\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5956 - accuracy: 0.7766 - val_loss: 0.8787 - val_accuracy: 0.5862\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5868 - accuracy: 0.7804 - val_loss: 0.8670 - val_accuracy: 0.5931\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.5800 - accuracy: 0.7804 - val_loss: 0.8568 - val_accuracy: 0.6138\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5730 - accuracy: 0.7842 - val_loss: 0.8474 - val_accuracy: 0.6276\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5642 - accuracy: 0.7888 - val_loss: 0.8390 - val_accuracy: 0.6345\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5575 - accuracy: 0.7904 - val_loss: 0.8307 - val_accuracy: 0.6414\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5512 - accuracy: 0.7942 - val_loss: 0.8226 - val_accuracy: 0.6276\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5440 - accuracy: 0.8011 - val_loss: 0.8176 - val_accuracy: 0.6276\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.5381 - accuracy: 0.8041 - val_loss: 0.8132 - val_accuracy: 0.6207\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5331 - accuracy: 0.8072 - val_loss: 0.8078 - val_accuracy: 0.6207\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.5256 - accuracy: 0.8110 - val_loss: 0.8041 - val_accuracy: 0.6276\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.5212 - accuracy: 0.8171 - val_loss: 0.7990 - val_accuracy: 0.6207\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5144 - accuracy: 0.8202 - val_loss: 0.7970 - val_accuracy: 0.6069\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.5078 - accuracy: 0.8194 - val_loss: 0.7943 - val_accuracy: 0.6138\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.5019 - accuracy: 0.8271 - val_loss: 0.7907 - val_accuracy: 0.6138\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.4979 - accuracy: 0.8286 - val_loss: 0.7897 - val_accuracy: 0.6138\n",
      "Epoch 47: early stopping\n",
      "Score for fold 4: loss of 0.7896905541419983; accuracy of 61.37930750846863%\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 92ms/step - loss: 1.2093 - accuracy: 0.3091 - val_loss: 1.1059 - val_accuracy: 0.3655\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 1.1233 - accuracy: 0.3527 - val_loss: 1.1060 - val_accuracy: 0.3448\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 1.0704 - accuracy: 0.4040 - val_loss: 1.1060 - val_accuracy: 0.3931\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 1.0329 - accuracy: 0.4392 - val_loss: 1.1060 - val_accuracy: 0.3586\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 1.0018 - accuracy: 0.4698 - val_loss: 1.1060 - val_accuracy: 0.3586\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9730 - accuracy: 0.4989 - val_loss: 1.1059 - val_accuracy: 0.3448\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9475 - accuracy: 0.5279 - val_loss: 1.1060 - val_accuracy: 0.3655\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9221 - accuracy: 0.5524 - val_loss: 1.1061 - val_accuracy: 0.3586\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.8974 - accuracy: 0.5769 - val_loss: 1.1062 - val_accuracy: 0.3586\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.8741 - accuracy: 0.5815 - val_loss: 1.1062 - val_accuracy: 0.3724\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.8533 - accuracy: 0.5930 - val_loss: 1.1056 - val_accuracy: 0.3655\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.8346 - accuracy: 0.6029 - val_loss: 1.1046 - val_accuracy: 0.3931\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.8179 - accuracy: 0.6205 - val_loss: 1.1035 - val_accuracy: 0.4138\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.8016 - accuracy: 0.6289 - val_loss: 1.1024 - val_accuracy: 0.4276\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.7852 - accuracy: 0.6427 - val_loss: 1.1002 - val_accuracy: 0.4414\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7706 - accuracy: 0.6488 - val_loss: 1.0971 - val_accuracy: 0.4552\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7582 - accuracy: 0.6526 - val_loss: 1.0933 - val_accuracy: 0.4552\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.7443 - accuracy: 0.6641 - val_loss: 1.0885 - val_accuracy: 0.4345\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7343 - accuracy: 0.6695 - val_loss: 1.0821 - val_accuracy: 0.4276\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7232 - accuracy: 0.6741 - val_loss: 1.0741 - val_accuracy: 0.4345\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7112 - accuracy: 0.6848 - val_loss: 1.0640 - val_accuracy: 0.4345\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7012 - accuracy: 0.6863 - val_loss: 1.0502 - val_accuracy: 0.4690\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.6915 - accuracy: 0.6886 - val_loss: 1.0372 - val_accuracy: 0.4690\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.6829 - accuracy: 0.7039 - val_loss: 1.0202 - val_accuracy: 0.4759\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.6747 - accuracy: 0.7008 - val_loss: 0.9990 - val_accuracy: 0.4897\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.6648 - accuracy: 0.7100 - val_loss: 0.9736 - val_accuracy: 0.5379\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.6557 - accuracy: 0.7116 - val_loss: 0.9467 - val_accuracy: 0.5448\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.6460 - accuracy: 0.7276 - val_loss: 0.9238 - val_accuracy: 0.5517\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.6400 - accuracy: 0.7322 - val_loss: 0.9012 - val_accuracy: 0.5862\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.6308 - accuracy: 0.7360 - val_loss: 0.8818 - val_accuracy: 0.5862\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.6224 - accuracy: 0.7337 - val_loss: 0.8595 - val_accuracy: 0.6069\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.6150 - accuracy: 0.7429 - val_loss: 0.8404 - val_accuracy: 0.6138\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.6083 - accuracy: 0.7475 - val_loss: 0.8272 - val_accuracy: 0.6138\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5999 - accuracy: 0.7559 - val_loss: 0.8154 - val_accuracy: 0.6069\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.5926 - accuracy: 0.7529 - val_loss: 0.8036 - val_accuracy: 0.6138\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5862 - accuracy: 0.7598 - val_loss: 0.7939 - val_accuracy: 0.6069\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.5790 - accuracy: 0.7636 - val_loss: 0.7845 - val_accuracy: 0.6207\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.5707 - accuracy: 0.7728 - val_loss: 0.7767 - val_accuracy: 0.6138\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5659 - accuracy: 0.7751 - val_loss: 0.7697 - val_accuracy: 0.6138\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5588 - accuracy: 0.7789 - val_loss: 0.7635 - val_accuracy: 0.6138\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.5505 - accuracy: 0.7881 - val_loss: 0.7580 - val_accuracy: 0.6138\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5451 - accuracy: 0.7972 - val_loss: 0.7505 - val_accuracy: 0.6069\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5389 - accuracy: 0.7972 - val_loss: 0.7464 - val_accuracy: 0.6069\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5327 - accuracy: 0.8026 - val_loss: 0.7433 - val_accuracy: 0.6069\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5271 - accuracy: 0.8011 - val_loss: 0.7450 - val_accuracy: 0.6069\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5224 - accuracy: 0.8057 - val_loss: 0.7408 - val_accuracy: 0.6069\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.5148 - accuracy: 0.8095 - val_loss: 0.7368 - val_accuracy: 0.6000\n",
      "Epoch 47: early stopping\n",
      "Score for fold 5: loss of 0.7368293404579163; accuracy of 60.00000238418579%\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 90ms/step - loss: 1.1952 - accuracy: 0.3535 - val_loss: 1.1021 - val_accuracy: 0.3103\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 1.1010 - accuracy: 0.4101 - val_loss: 1.0980 - val_accuracy: 0.3103\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 1.0355 - accuracy: 0.4621 - val_loss: 1.0941 - val_accuracy: 0.3103\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.9831 - accuracy: 0.5011 - val_loss: 1.0907 - val_accuracy: 0.3103\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.9438 - accuracy: 0.5356 - val_loss: 1.0876 - val_accuracy: 0.3103\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.9119 - accuracy: 0.5539 - val_loss: 1.0853 - val_accuracy: 0.3103\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.8831 - accuracy: 0.5792 - val_loss: 1.0839 - val_accuracy: 0.3103\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.8590 - accuracy: 0.5937 - val_loss: 1.0832 - val_accuracy: 0.3103\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.8380 - accuracy: 0.6197 - val_loss: 1.0833 - val_accuracy: 0.3103\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.8180 - accuracy: 0.6259 - val_loss: 1.0843 - val_accuracy: 0.3103\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.7999 - accuracy: 0.6381 - val_loss: 1.0861 - val_accuracy: 0.3103\n",
      "Epoch 11: early stopping\n",
      "Score for fold 6: loss of 1.0860551595687866; accuracy of 31.034481525421143%\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 3s 138ms/step - loss: 1.2086 - accuracy: 0.3841 - val_loss: 1.1055 - val_accuracy: 0.3655\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 1.1279 - accuracy: 0.4178 - val_loss: 1.1048 - val_accuracy: 0.3862\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 1.0723 - accuracy: 0.4415 - val_loss: 1.1043 - val_accuracy: 0.3931\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 1.0307 - accuracy: 0.4690 - val_loss: 1.1038 - val_accuracy: 0.3931\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.9993 - accuracy: 0.4828 - val_loss: 1.1034 - val_accuracy: 0.3655\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.9690 - accuracy: 0.5080 - val_loss: 1.1030 - val_accuracy: 0.3103\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.9452 - accuracy: 0.5233 - val_loss: 1.1022 - val_accuracy: 0.3517\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9255 - accuracy: 0.5432 - val_loss: 1.1006 - val_accuracy: 0.3448\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.9057 - accuracy: 0.5593 - val_loss: 1.0987 - val_accuracy: 0.4207\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.8909 - accuracy: 0.5738 - val_loss: 1.0968 - val_accuracy: 0.4414\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.8718 - accuracy: 0.5853 - val_loss: 1.0947 - val_accuracy: 0.4207\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.8551 - accuracy: 0.5960 - val_loss: 1.0929 - val_accuracy: 0.4138\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.8392 - accuracy: 0.6060 - val_loss: 1.0903 - val_accuracy: 0.4138\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.8257 - accuracy: 0.6190 - val_loss: 1.0881 - val_accuracy: 0.4207\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.8111 - accuracy: 0.6266 - val_loss: 1.0854 - val_accuracy: 0.4207\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.7975 - accuracy: 0.6435 - val_loss: 1.0817 - val_accuracy: 0.4138\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7851 - accuracy: 0.6534 - val_loss: 1.0765 - val_accuracy: 0.4138\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.7712 - accuracy: 0.6641 - val_loss: 1.0711 - val_accuracy: 0.4345\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.7590 - accuracy: 0.6679 - val_loss: 1.0633 - val_accuracy: 0.4690\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.7459 - accuracy: 0.6787 - val_loss: 1.0529 - val_accuracy: 0.4759\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.7368 - accuracy: 0.6832 - val_loss: 1.0363 - val_accuracy: 0.4897\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.7250 - accuracy: 0.6924 - val_loss: 1.0200 - val_accuracy: 0.5034\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7142 - accuracy: 0.7031 - val_loss: 1.0008 - val_accuracy: 0.5034\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.7028 - accuracy: 0.7169 - val_loss: 0.9844 - val_accuracy: 0.5172\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.6943 - accuracy: 0.7070 - val_loss: 0.9619 - val_accuracy: 0.5310\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.6835 - accuracy: 0.7184 - val_loss: 0.9364 - val_accuracy: 0.5379\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.6742 - accuracy: 0.7238 - val_loss: 0.9108 - val_accuracy: 0.5655\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.6669 - accuracy: 0.7230 - val_loss: 0.8895 - val_accuracy: 0.5724\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.6559 - accuracy: 0.7422 - val_loss: 0.8665 - val_accuracy: 0.6000\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.6479 - accuracy: 0.7414 - val_loss: 0.8480 - val_accuracy: 0.6138\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.6408 - accuracy: 0.7483 - val_loss: 0.8289 - val_accuracy: 0.6345\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.6296 - accuracy: 0.7552 - val_loss: 0.8154 - val_accuracy: 0.6621\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.6222 - accuracy: 0.7613 - val_loss: 0.8018 - val_accuracy: 0.6690\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.6131 - accuracy: 0.7758 - val_loss: 0.7917 - val_accuracy: 0.6621\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.6086 - accuracy: 0.7758 - val_loss: 0.7813 - val_accuracy: 0.6552\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.5990 - accuracy: 0.7819 - val_loss: 0.7654 - val_accuracy: 0.6759\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.5898 - accuracy: 0.7850 - val_loss: 0.7525 - val_accuracy: 0.6828\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5839 - accuracy: 0.7865 - val_loss: 0.7428 - val_accuracy: 0.6759\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5737 - accuracy: 0.8018 - val_loss: 0.7366 - val_accuracy: 0.6759\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5667 - accuracy: 0.7972 - val_loss: 0.7349 - val_accuracy: 0.6828\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5596 - accuracy: 0.8110 - val_loss: 0.7302 - val_accuracy: 0.6828\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5526 - accuracy: 0.8164 - val_loss: 0.7231 - val_accuracy: 0.6759\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5465 - accuracy: 0.8225 - val_loss: 0.7143 - val_accuracy: 0.6897\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.5404 - accuracy: 0.8233 - val_loss: 0.7082 - val_accuracy: 0.6759\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5336 - accuracy: 0.8286 - val_loss: 0.7077 - val_accuracy: 0.6897\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.5270 - accuracy: 0.8370 - val_loss: 0.7045 - val_accuracy: 0.6897\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.5199 - accuracy: 0.8309 - val_loss: 0.7020 - val_accuracy: 0.6897\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.5142 - accuracy: 0.8370 - val_loss: 0.7003 - val_accuracy: 0.6897\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.5085 - accuracy: 0.8470 - val_loss: 0.6964 - val_accuracy: 0.6897\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.5023 - accuracy: 0.8500 - val_loss: 0.6936 - val_accuracy: 0.6897\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.4966 - accuracy: 0.8592 - val_loss: 0.6914 - val_accuracy: 0.6828\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.4924 - accuracy: 0.8493 - val_loss: 0.6909 - val_accuracy: 0.6828\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.4858 - accuracy: 0.8546 - val_loss: 0.6889 - val_accuracy: 0.6759\n",
      "Epoch 53: early stopping\n",
      "Score for fold 7: loss of 0.6889495849609375; accuracy of 67.58620738983154%\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 94ms/step - loss: 1.2232 - accuracy: 0.2953 - val_loss: 1.1068 - val_accuracy: 0.3103\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 1.1556 - accuracy: 0.3305 - val_loss: 1.1077 - val_accuracy: 0.4207\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 1.1113 - accuracy: 0.3680 - val_loss: 1.1087 - val_accuracy: 0.3517\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 1.0786 - accuracy: 0.4009 - val_loss: 1.1099 - val_accuracy: 0.3448\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 1.0500 - accuracy: 0.4277 - val_loss: 1.1112 - val_accuracy: 0.3517\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 1.0257 - accuracy: 0.4499 - val_loss: 1.1125 - val_accuracy: 0.3517\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 1.0039 - accuracy: 0.4728 - val_loss: 1.1140 - val_accuracy: 0.3517\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9829 - accuracy: 0.4866 - val_loss: 1.1156 - val_accuracy: 0.3517\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.9646 - accuracy: 0.5011 - val_loss: 1.1173 - val_accuracy: 0.3517\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9487 - accuracy: 0.5256 - val_loss: 1.1193 - val_accuracy: 0.3586\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.9331 - accuracy: 0.5363 - val_loss: 1.1211 - val_accuracy: 0.3724\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9195 - accuracy: 0.5463 - val_loss: 1.1226 - val_accuracy: 0.3793\n",
      "Epoch 12: early stopping\n",
      "Score for fold 8: loss of 1.1225584745407104; accuracy of 37.931033968925476%\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 93ms/step - loss: 1.1803 - accuracy: 0.3764 - val_loss: 1.1053 - val_accuracy: 0.3517\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 1.0968 - accuracy: 0.4308 - val_loss: 1.1048 - val_accuracy: 0.3103\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 1.0417 - accuracy: 0.4682 - val_loss: 1.1042 - val_accuracy: 0.3034\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 1.0011 - accuracy: 0.4943 - val_loss: 1.1035 - val_accuracy: 0.3103\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.9651 - accuracy: 0.5233 - val_loss: 1.1029 - val_accuracy: 0.3103\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9370 - accuracy: 0.5425 - val_loss: 1.1021 - val_accuracy: 0.3103\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9111 - accuracy: 0.5578 - val_loss: 1.1014 - val_accuracy: 0.3103\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.8888 - accuracy: 0.5700 - val_loss: 1.1007 - val_accuracy: 0.3103\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.8705 - accuracy: 0.5868 - val_loss: 1.1001 - val_accuracy: 0.3103\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.8486 - accuracy: 0.5945 - val_loss: 1.0993 - val_accuracy: 0.3103\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.8311 - accuracy: 0.6067 - val_loss: 1.0984 - val_accuracy: 0.3103\n",
      "Epoch 11: early stopping\n",
      "Score for fold 9: loss of 1.0984349250793457; accuracy of 31.034481525421143%\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 94ms/step - loss: 1.2016 - accuracy: 0.3405 - val_loss: 1.1055 - val_accuracy: 0.3379\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 1.1230 - accuracy: 0.3757 - val_loss: 1.1052 - val_accuracy: 0.3379\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 1.0833 - accuracy: 0.4116 - val_loss: 1.1050 - val_accuracy: 0.3379\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 1.0534 - accuracy: 0.4422 - val_loss: 1.1049 - val_accuracy: 0.3379\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 1.0343 - accuracy: 0.4621 - val_loss: 1.1049 - val_accuracy: 0.3379\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 1.0150 - accuracy: 0.4721 - val_loss: 1.1051 - val_accuracy: 0.3655\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.9986 - accuracy: 0.4996 - val_loss: 1.1054 - val_accuracy: 0.3793\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9848 - accuracy: 0.5103 - val_loss: 1.1058 - val_accuracy: 0.3724\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9713 - accuracy: 0.5325 - val_loss: 1.1065 - val_accuracy: 0.2897\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9591 - accuracy: 0.5356 - val_loss: 1.1070 - val_accuracy: 0.2759\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.9475 - accuracy: 0.5555 - val_loss: 1.1067 - val_accuracy: 0.2759\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.9361 - accuracy: 0.5662 - val_loss: 1.1059 - val_accuracy: 0.2966\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.9253 - accuracy: 0.5754 - val_loss: 1.1036 - val_accuracy: 0.3586\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.9156 - accuracy: 0.5884 - val_loss: 1.1001 - val_accuracy: 0.4069\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.9061 - accuracy: 0.5953 - val_loss: 1.0964 - val_accuracy: 0.4138\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.8974 - accuracy: 0.6098 - val_loss: 1.0932 - val_accuracy: 0.4138\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.8886 - accuracy: 0.6121 - val_loss: 1.0888 - val_accuracy: 0.4069\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.8804 - accuracy: 0.6266 - val_loss: 1.0837 - val_accuracy: 0.4138\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.8710 - accuracy: 0.6335 - val_loss: 1.0788 - val_accuracy: 0.4138\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.8635 - accuracy: 0.6458 - val_loss: 1.0734 - val_accuracy: 0.4207\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.8549 - accuracy: 0.6496 - val_loss: 1.0678 - val_accuracy: 0.4207\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.8483 - accuracy: 0.6649 - val_loss: 1.0626 - val_accuracy: 0.4414\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.8396 - accuracy: 0.6702 - val_loss: 1.0561 - val_accuracy: 0.4414\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.8326 - accuracy: 0.6779 - val_loss: 1.0479 - val_accuracy: 0.4483\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.8256 - accuracy: 0.6802 - val_loss: 1.0378 - val_accuracy: 0.4552\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.8199 - accuracy: 0.6886 - val_loss: 1.0267 - val_accuracy: 0.4483\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.8127 - accuracy: 0.7016 - val_loss: 1.0162 - val_accuracy: 0.5034\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.8053 - accuracy: 0.7108 - val_loss: 1.0046 - val_accuracy: 0.5310\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7988 - accuracy: 0.7184 - val_loss: 0.9910 - val_accuracy: 0.5379\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.7923 - accuracy: 0.7238 - val_loss: 0.9792 - val_accuracy: 0.5448\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.7860 - accuracy: 0.7261 - val_loss: 0.9674 - val_accuracy: 0.5517\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7794 - accuracy: 0.7353 - val_loss: 0.9545 - val_accuracy: 0.5655\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7741 - accuracy: 0.7406 - val_loss: 0.9416 - val_accuracy: 0.5517\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7664 - accuracy: 0.7437 - val_loss: 0.9284 - val_accuracy: 0.5724\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.7607 - accuracy: 0.7475 - val_loss: 0.9181 - val_accuracy: 0.5931\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.7535 - accuracy: 0.7521 - val_loss: 0.9078 - val_accuracy: 0.6138\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.7480 - accuracy: 0.7552 - val_loss: 0.9009 - val_accuracy: 0.6414\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7421 - accuracy: 0.7613 - val_loss: 0.8931 - val_accuracy: 0.6414\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.7369 - accuracy: 0.7674 - val_loss: 0.8855 - val_accuracy: 0.6483\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.7300 - accuracy: 0.7728 - val_loss: 0.8783 - val_accuracy: 0.6414\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7252 - accuracy: 0.7804 - val_loss: 0.8715 - val_accuracy: 0.6483\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.7180 - accuracy: 0.7827 - val_loss: 0.8652 - val_accuracy: 0.6345\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7134 - accuracy: 0.7865 - val_loss: 0.8602 - val_accuracy: 0.6276\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.7078 - accuracy: 0.7888 - val_loss: 0.8563 - val_accuracy: 0.6207\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.7023 - accuracy: 0.7934 - val_loss: 0.8534 - val_accuracy: 0.6138\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.6962 - accuracy: 0.7980 - val_loss: 0.8487 - val_accuracy: 0.6069\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.6907 - accuracy: 0.8003 - val_loss: 0.8439 - val_accuracy: 0.6000\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.6847 - accuracy: 0.8011 - val_loss: 0.8401 - val_accuracy: 0.6138\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.6799 - accuracy: 0.8072 - val_loss: 0.8358 - val_accuracy: 0.6138\n",
      "Epoch 49: early stopping\n",
      "Score for fold 10: loss of 0.8358321785926819; accuracy of 61.37930750846863%\n"
     ]
    }
   ],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu', padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(BatchNormalization())\n",
    "    cnn3.add(AveragePooling3D(padding='same'))\n",
    "    #cnn3.add(Dropout(rate=0.5))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(BatchNormalization())\n",
    "    cnn3.add(AveragePooling3D(padding='same'))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(BatchNormalization())\n",
    "    cnn3.add(AveragePooling3D(padding='same'))\n",
    "    \n",
    "    cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(BatchNormalization())\n",
    "    cnn3.add(AveragePooling3D(padding='same'))\n",
    "    \n",
    "    cnn3.add(Conv3D(128, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(BatchNormalization())\n",
    "    cnn3.add(AveragePooling3D(padding='same'))\n",
    "    #cnn3.add(Dropout(rate=0.5))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10)\n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(8, activation='relu', kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "                    bias_regularizer=regularizers.L2(1e-4),\n",
    "                    activity_regularizer=regularizers.L2(1e-5)))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= 3, activation = 'softmax')) #units is always equal to number of classes\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.00001) # learning_rate\n",
    "    sgd=keras.optimizers.SGD(lr=0.0001)\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=100 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  batch_size=100, epochs=epochs, verbose=1, shuffle=True, callbacks=[es],\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    #gc.collect()\n",
    "    #K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "color-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cnn3.predict((X_train_reshape), batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "seven-chain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1452, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "duplicate-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.argmax ( pred , axis=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "agreed-truth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2 ... 0 1 0]\n",
      "[0 2 0 ... 0 1 2]\n",
      "1147 out of 1452\n"
     ]
    }
   ],
   "source": [
    "print(predicted)\n",
    "y_true=np.argmax (y_train , axis=-1 )\n",
    "print(y_true)\n",
    "\n",
    "cnt=0\n",
    "for i,p in enumerate(predicted):\n",
    "    if (p==y_true[i]):\n",
    "        cnt=cnt+1\n",
    "\n",
    "#print(cnt, 'out of 201')\n",
    "print(cnt, 'out of 1452')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "comparable-wagner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 1 1 0 2 1 2 1 2 0 2 1 0 2 2 0 2 0 2 0 0 0 0 0 0 2 2 2 2 0 1 0 1 2 0\n",
      " 2 2 0 2 0 0 0 1 0 1 0 1 2 2 1 2 0 2 0 1 2 0 2 2 2 1 2 0 2 2 1 0 1 0 2 2 0\n",
      " 2 2 0 2 0 0 0 2 1 2 0 1 0 0 1 0 0 2 2 2 1 2 1 2 1 1 0 1 2 2 0 1 2 2 2 1 1\n",
      " 0 2 2 0 2 2 0 1 0 0 1 0 2 2 0 0 0 1 1 1 2 2 2 1 0 0 2 0 1 1 0 2 1 2 1 2 2\n",
      " 0 1 0 2 2 1 2 0 1 0 2 0 2 0 2 0 2 0 2 0 0 0 0 2 2 1 0 0 0 0 2 0 2 1 1 2 1\n",
      " 0 2 2 1 0 0 1 1 2 0 2 0 2 1 2 2 1 1 1 0 1 1 1 1 2 2 0 1 2 2 2 0 2 1 0 0 0\n",
      " 2 2 1 2 0 2 0 1 0 1 2 0 2 0 2 1 2 1 2 0 0 2 1 0 1 2 0 2 0 2 2 2 2 2 0 1 2\n",
      " 0 0 1 1 0 2 1 2 1 2 2 0 1 0 2 2 1 0 0 2 2 1 2 0 1 2 2 1 1 2 2 0 0 2 0 0 2\n",
      " 1 1 1 0 0 0 2 1 2 1 0 1 2 2 1 1 1 1 2 2 2 1 0 1 2 0 0 0 2 0 1 0 2 2 0 2 0\n",
      " 1 1 1 2 1 0 2 2 0 0 0 1 0 0 0 0 1 2 2 1 1 2 1 2 0 2 1 2 0 1]\n",
      "[1 2 1 1 1 0 2 0 2 1 2 0 1 1 0 0 2 1 2 0 2 1 1 1 1 2 0 2 2 0 2 0 1 0 0 2 0\n",
      " 0 0 1 2 0 1 0 0 0 0 2 1 2 2 0 2 1 2 0 1 2 0 2 2 1 0 0 0 2 0 1 0 1 0 0 2 0\n",
      " 2 0 0 0 1 0 1 2 1 0 0 0 0 0 0 0 2 2 2 2 0 0 1 2 1 0 0 1 2 2 1 1 0 0 2 1 1\n",
      " 2 2 2 1 2 2 1 1 0 0 0 2 2 2 1 0 1 1 0 0 2 2 0 0 0 0 0 1 1 1 1 0 1 2 0 2 2\n",
      " 2 0 0 0 2 1 2 0 1 0 0 2 0 0 0 0 0 0 0 1 0 1 1 2 2 1 0 1 2 0 0 2 0 1 1 0 0\n",
      " 1 0 0 0 2 0 1 1 0 1 2 1 0 0 2 1 1 1 1 0 1 1 1 1 0 2 1 1 2 2 2 0 0 0 1 2 2\n",
      " 2 2 1 2 1 1 0 1 0 0 1 1 0 1 2 2 2 1 2 0 1 0 1 2 1 2 2 2 2 0 0 2 0 1 0 1 2\n",
      " 0 0 0 1 0 2 1 2 0 0 0 2 1 1 2 2 1 1 0 2 2 1 0 0 1 2 2 1 1 2 0 0 0 0 1 0 2\n",
      " 0 1 1 0 2 0 2 1 2 1 1 1 2 0 0 1 1 1 0 1 2 1 2 1 2 0 0 1 2 1 0 1 2 2 2 2 2\n",
      " 1 1 1 0 1 2 1 2 2 1 2 0 0 0 0 1 1 2 2 1 0 0 0 0 0 2 0 0 0 1]\n",
      "214 out of 363\n"
     ]
    }
   ],
   "source": [
    "pred_test = cnn3.predict(X_test_reshape, batch_size=10)\n",
    "ytestPred=np.argmax ( pred_test , axis=-1 )\n",
    "ytruePred=np.argmax ( y_test , axis=-1 )\n",
    "print(ytestPred)\n",
    "print(ytruePred)\n",
    "\n",
    "cnt=0\n",
    "for i,p in enumerate(ytestPred):\n",
    "    if (p==ytruePred[i]):\n",
    "        cnt=cnt+1\n",
    "\n",
    "#print(cnt,'out of 51')\n",
    "print(cnt,'out of 363')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "legal-venezuela",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.446     0.500     0.471       124\n",
      "           1      0.586     0.687     0.633        99\n",
      "           2      0.778     0.600     0.677       140\n",
      "\n",
      "    accuracy                          0.590       363\n",
      "   macro avg      0.603     0.596     0.594       363\n",
      "weighted avg      0.612     0.590     0.595       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print the confusion matrix\n",
    "#print(metrics.confusion_matrix(ytestPred,ytruePred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(ytestPred,ytruePred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "funded-riverside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'], label='train')\n",
    "plt.plot(hist.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-showcase",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-printing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-climate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-alias",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-interference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-finnish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-exhibit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-failing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-desire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu', padding='same',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                    bias_regularizer=regularizers.l2(1e-4),\n",
    "                    activity_regularizer=regularizers.l2(1e-5),\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(16, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.2))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=1e-4) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=100 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-asset",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-friend",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-participation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "effective-richmond",
   "metadata": {},
   "source": [
    "# Change to sheet 3 on google sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-boulder",
   "metadata": {},
   "source": [
    "# Models 1,2,3 (change epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "        \n",
    "# Define 10-fold cross validation test harness\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(8, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=10 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "        \n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=10, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-covering",
   "metadata": {},
   "source": [
    "# Models 4, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    \n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu', padding='same',  kernel_regularizer=regularizers.l2(l=0.01),\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same',  kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    #cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same',  kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    #cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(8, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #sgd=keras.optimizers.SGD(lr=0.0001)\n",
    "    #adadelta=keras.optimizers.Adadelta(learning_rate=0.001)\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=100 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test],y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-nebraska",
   "metadata": {},
   "source": [
    "# Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    \n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu', padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    #cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same',  kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    #cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(8, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.2))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #sgd=keras.optimizers.SGD(lr=0.0001)\n",
    "    #adadelta=keras.optimizers.Adadelta(learning_rate=0.001)\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=100 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test],y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-inspector",
   "metadata": {},
   "source": [
    "# Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu', padding='same',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                    bias_regularizer=regularizers.l2(1e-4),\n",
    "                    activity_regularizer=regularizers.l2(1e-5),\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    #cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    #cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    #cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    #cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    #cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    #cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=1e-4) # learning_rate\n",
    "    #sgd=keras.optimizers.SGD(lr=0.0001)\n",
    "    #adadelta=keras.optimizers.Adadelta(learning_rate=0.001)\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=100 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-setting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-serial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-longitude",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-excess",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-furniture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-smoke",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-integrity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-simpson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-pollution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-music",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-providence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_gpu",
   "language": "python",
   "name": "test_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
