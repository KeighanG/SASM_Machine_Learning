{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-durham",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "responsible-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import gc\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import dask\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import s3fs\n",
    "import zarr\n",
    "import geocat.comp\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from math import e\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv3D, Flatten,MaxPooling3D,AveragePooling3D, concatenate,Input ,SpatialDropout3D,Dropout\n",
    "from sklearn import metrics\n",
    "from keras import backend as K\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.constraints import unit_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exterior-dinner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: /physical_device:GPU:0   Type: GPU\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)\n",
    "    \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metallic-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing functions\n",
    "#3D detrend function\n",
    "def detrend(x:np.ndarray,time:np.ndarray):\n",
    "        nt,nx,ny = x.shape\n",
    "        xtemp = x.reshape(nt,nx*ny)\n",
    "        p = np.polyfit(time, xtemp, deg=3)\n",
    "        fit = p[0]*(time[:,np.newaxis] **3)+ p[1]*(time[:,np.newaxis]**2) + p[2]*(time[:,np.newaxis]) + p[3]\n",
    "        return x - fit.reshape(nt,nx,ny)\n",
    "    \n",
    "#1D detrend function\n",
    "def altdetrend(x:np.ndarray,time:np.ndarray):\n",
    "        nt = x.shape\n",
    "        xtemp = x.reshape(nt)\n",
    "        p = np.polyfit(time, x, deg=1)\n",
    "        fit = p[0]*(time[:,np.newaxis])+ p[1]\n",
    "        return x - fit.reshape(nt)\n",
    "    \n",
    "def remove_time_mean(x):\n",
    "        return x - x.mean(dim='time')\n",
    "\n",
    "def removeSC(x):\n",
    "        return x.groupby('time.month').apply(remove_time_mean)\n",
    "\n",
    "# Calculate std normal anomaly\n",
    "def calStdNorAnom(x):\n",
    "    a=[]\n",
    "    for m in np.unique(x.time.dt.month):\n",
    "        mData=x[x.time.dt.month==m]\n",
    "        mRolling=mData.rolling(time=31, center=True).mean().bfill(dim=\"time\").ffill(dim=\"time\")\n",
    "        sRolling=mData.rolling(time=31, center=True).std().bfill(dim=\"time\").ffill(dim=\"time\")\n",
    "        normData=(mData-mRolling)/sRolling\n",
    "        a.append(normData)\n",
    "    combineArray=xr.concat(a,'time')\n",
    "    outArray=combineArray.sortby('time')\n",
    "    return outArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recovered-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to AWS S3 storage\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "## By downloading the master CSV file enumerating all available data stores, we can interact with the spreadsheet\n",
    "## through a pandas DataFrame to search and explore for relevant data using the CMIP6 controlled vocabulary:\n",
    "df = pd.read_csv(\"https://cmip6-pds.s3.amazonaws.com/pangeo-cmip6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "talented-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(qstring):\n",
    "    df_subset = df.query(qstring)\n",
    "    if df_subset.empty:\n",
    "        print('data not available for '+qstring)\n",
    "    else:\n",
    "        for v in df_subset.zstore.values:\n",
    "            zstore = v\n",
    "            mapper = fs.get_mapper(zstore)\n",
    "            return_ds = xr.open_zarr(mapper, consolidated=True)\n",
    "    return(return_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "previous-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open CESM2 Ensemble Datasets\n",
    "modelName=\"'CESM2'\"\n",
    "institute=\"'NCAR'\"\n",
    "expList=[\"'historical'\"]\n",
    "actList=[\"'CMIP'\"]\n",
    "membList=[\"'r1i1p1f1'\", \"'r2i1p1f1'\", \"'r3i1p1f1'\", \"'r4i1p1f1'\" , \"'r5i1p1f1'\", \"'r6i1p1f1'\", \"'r7i1p1f1'\",\"'r8i1p1f1'\",\"'r9i1p1f1'\",\"'r10i1p1f1'\",\"'r11i1p1f1'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "literary-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "creslist=[]\n",
    "crellist=[]\n",
    "netTOAcslist=[]\n",
    "dummy_ylist=[]\n",
    "\n",
    "for j,memb in enumerate(membList):\n",
    "        inputStr  = \"institution_id =='NCAR' & source_id=='CESM2' & table_id=='Amon' & experiment_id=='historical' &  member_id==\"+memb+\" & variable_id==\"\n",
    "        altinputStr  = \"activity_id=='CMIP' & table_id=='fx' & source_id=='CESM2' & experiment_id=='historical' &  member_id==\"+memb+\" & variable_id==\"\n",
    "        rsut_ds   = getData(inputStr+\"'rsut'\")\n",
    "        pr_ds     = getData(inputStr+\"'pr'\")\n",
    "        rsutcs_ds = getData(inputStr+\"'rsutcs'\")\n",
    "        sftlf_ds = getData(altinputStr+\"'sftlf'\")\n",
    "        rlut_ds   =getData(inputStr+\"'rlut'\")\n",
    "        rlutcs_ds  =getData(inputStr+\"'rlutcs'\")\n",
    "        rsdt_ds  =getData(inputStr+\"'rsdt'\")\n",
    "        \n",
    "        netTOAcs = rsdt_ds.rsdt - rsutcs_ds.rsutcs - rlutcs_ds.rlutcs\n",
    "        \n",
    "        cres= rsutcs_ds.rsutcs-rsut_ds.rsut\n",
    "        crel=rlutcs_ds.rlutcs-rlut_ds.rlut\n",
    "        prec=pr_ds.pr\n",
    "        land=sftlf_ds.sftlf\n",
    "    \n",
    "        datetimeindex=cres.indexes['time'].to_datetimeindex()\n",
    "        cres['time']=datetimeindex\n",
    "        crel['time']=datetimeindex\n",
    "        netTOAcs['time']=datetimeindex\n",
    "        prec['time']=datetimeindex\n",
    "        \n",
    "        cres,land= xr.broadcast(cres,land) #add time dimension to land variable for compatability with CRE variables\n",
    "        \n",
    "        #Try just selecting the indian ocean\n",
    "        cres=cres.sel(lat=slice(-40,10))\n",
    "        crel=crel.sel(lat=slice(-40,10))\n",
    "        netTOAcs=netTOAcs.sel(lat=slice(-40,10))\n",
    "\n",
    "        cres=cres.sel(lon=slice(40,115))\n",
    "        crel=crel.sel(lon=slice(40,115))\n",
    "        netTOAcs=netTOAcs.sel(lon=slice(40,115))\n",
    "        \n",
    "        \n",
    "        \n",
    "        months=[6,7,8,9]\n",
    "        leadmonths=[2,3,4,5]\n",
    "\n",
    "        #varOut.where(varOut.time.dt.month.isin(months), drop=True) #Change varOut to desired variable\n",
    "        prec=prec.sel(time=prec.time.dt.month.isin(months))\n",
    "        cres=cres.sel(time=cres.time.dt.month.isin(leadmonths))\n",
    "        crel=crel.sel(time=crel.time.dt.month.isin(leadmonths))\n",
    "        netTOAcs=netTOAcs.sel(time=netTOAcs.time.dt.month.isin(leadmonths))\n",
    "        land=land.sel(time=land.time.dt.month.isin(months))\n",
    "        \n",
    "        #Select only the SAM lat,lon range: 60-100E, 10-30N\n",
    "        precip=prec.sel(lon=slice(60,100),lat=slice(10,30))\n",
    "        land=land.sel(lon=slice(60,100),lat=slice(10,30))\n",
    "        \n",
    "        precip=xr.where(land==0,np.nan,precip) #remove oceans, monsoon is defined as only over land \n",
    "        \n",
    "        #Do weighted correction on precipitation\n",
    "        weights=np.cos(np.deg2rad(precip.lat))\n",
    "        prec_index=precip.weighted(weights).mean(dim=('lat','lon'))\n",
    "        prec_index=prec_index*60*60*24 #conversion to mm/day, exluding dividing by rho and multiplying by 1000mm/m\n",
    "        \n",
    "        lat=cres.lat\n",
    "        lon=cres.lon\n",
    "        \n",
    "        #Do the preprocessing\n",
    "        cres=removeSC(cres)\n",
    "        cres=calStdNorAnom(cres)\n",
    "        \n",
    "        crel=removeSC(crel)\n",
    "        crel=calStdNorAnom(crel)\n",
    "        \n",
    "        netTOAcs=removeSC(netTOAcs)\n",
    "        netTOAcs=calStdNorAnom(netTOAcs)\n",
    "        \n",
    "        #Detrend\n",
    "        time=cres.time\n",
    "        cres=cres.to_numpy()\n",
    "        crel=crel.to_numpy()\n",
    "        netTOAcs=netTOAcs.to_numpy()\n",
    "        time=time.to_numpy()\n",
    "        time=time.astype(int)/10**9\n",
    "        \n",
    "        cres=detrend(cres,time)\n",
    "        cres=xr.DataArray(cres,coords=[time,lat,lon],dims=['time','lat','lon'])\n",
    "        \n",
    "        crel=detrend(crel,time)\n",
    "        crel=xr.DataArray(crel,coords=[time,lat,lon],dims=['time','lat','lon'])\n",
    "        \n",
    "        netTOAcs=detrend(netTOAcs,time)\n",
    "        netTOAcs=xr.DataArray(netTOAcs,coords=[time,lat,lon],dims=['time','lat','lon'])\n",
    "        \n",
    "        #Precip preprocessing\n",
    "        #Remove seasonal cycle\n",
    "        prec_index=removeSC(prec_index)\n",
    "        \n",
    "        #Normalize\n",
    "        prec_index=calStdNorAnom(prec_index)\n",
    "        \n",
    "        #Detrend\n",
    "        time=prec_index.time\n",
    "        prec_index=prec_index.to_numpy()\n",
    "        time=time.to_numpy()\n",
    "        time=time.astype(int)/10**9\n",
    "        \n",
    "        prec_index=altdetrend(prec_index,time)\n",
    "        prec_index=xr.DataArray(prec_index,coords=[time],dims=['time'])\n",
    "        \n",
    "        mysd=prec_index.std()\n",
    "        mymean=prec_index.mean()\n",
    "\n",
    "        buckets=pd.Categorical(pd.cut(prec_index, [mymean - mysd* 10000,  mymean - 0.5*mysd,  mymean + 0.5*mysd, mymean + mysd* 10000])).rename_categories(['low','average','high'])\n",
    "\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(buckets)\n",
    "\n",
    "        labelprec=le.transform(buckets)\n",
    "\n",
    "        # convert integers to dummy variables (i.e. one hot encoded)\n",
    "        nclasses=3\n",
    "        dummy_y=to_categorical(labelprec,nclasses) #converts to binary\n",
    "        \n",
    "        creslist.append(cres)\n",
    "        cresstack=np.stack(creslist,axis=0)\n",
    "        \n",
    "        crellist.append(crel)\n",
    "        crelstack=np.stack(crellist,axis=0)\n",
    "        \n",
    "        netTOAcslist.append(netTOAcs)\n",
    "        netTOAcsstack=np.stack(netTOAcslist,axis=0)\n",
    "        \n",
    "        dummy_ylist.append(dummy_y)\n",
    "        dummy_ystack=np.stack(dummy_ylist,axis=0)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "humanitarian-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate each cres array\n",
    "cresIn1=cresstack[0,:,:,:]\n",
    "cresIn2=cresstack[1,:,:,:]\n",
    "cresIn3=cresstack[2,:,:,:]\n",
    "cresIn4=cresstack[3,:,:,:]\n",
    "cresIn5=cresstack[4,:,:,:]\n",
    "cresIn6=cresstack[5,:,:,:]\n",
    "cresIn7=cresstack[6,:,:,:]\n",
    "cresIn8=cresstack[7,:,:,:]\n",
    "cresIn9=cresstack[8,:,:,:]\n",
    "cresIn10=cresstack[9,:,:,:]\n",
    "cresIn11=cresstack[10,:,:,:]\n",
    "\n",
    "\n",
    "#Concatenate the ensemble members along time axis\n",
    "cresIn=np.concatenate((cresIn1,cresIn2,cresIn3,cresIn4,cresIn5,cresIn6,cresIn7,cresIn8,cresIn9,cresIn10,cresIn11),axis=0)\n",
    "\n",
    "#Seperate each crel array\n",
    "crelIn1=crelstack[0,:,:,:]\n",
    "crelIn2=crelstack[1,:,:,:]\n",
    "crelIn3=crelstack[2,:,:,:]\n",
    "crelIn4=crelstack[3,:,:,:]\n",
    "crelIn5=crelstack[4,:,:,:]\n",
    "crelIn6=crelstack[5,:,:,:]\n",
    "crelIn7=crelstack[6,:,:,:]\n",
    "crelIn8=crelstack[7,:,:,:]\n",
    "crelIn9=crelstack[8,:,:,:]\n",
    "crelIn10=crelstack[9,:,:,:]\n",
    "crelIn11=crelstack[10,:,:,:]\n",
    "\n",
    "#Concatenate the ensemble members along time axis\n",
    "crelIn=np.concatenate((crelIn1,crelIn2,crelIn3,crelIn4,crelIn5,crelIn6,crelIn7,crelIn8,crelIn9,crelIn10,crelIn11),axis=0)\n",
    "\n",
    "#Seperate each netTOAcs array\n",
    "netTOAcsIn1=netTOAcsstack[0,:,:,:]\n",
    "netTOAcsIn2=netTOAcsstack[1,:,:,:]\n",
    "netTOAcsIn3=netTOAcsstack[2,:,:,:]\n",
    "netTOAcsIn4=netTOAcsstack[3,:,:,:]\n",
    "netTOAcsIn5=netTOAcsstack[4,:,:,:]\n",
    "netTOAcsIn6=netTOAcsstack[5,:,:,:]\n",
    "netTOAcsIn7=netTOAcsstack[6,:,:,:]\n",
    "netTOAcsIn8=netTOAcsstack[7,:,:,:]\n",
    "netTOAcsIn9=netTOAcsstack[8,:,:,:]\n",
    "netTOAcsIn10=netTOAcsstack[9,:,:,:]\n",
    "netTOAcsIn11=netTOAcsstack[10,:,:,:]\n",
    "\n",
    "#Concatenate the ensemble members along time axis\n",
    "netTOAcsIn=np.concatenate((netTOAcsIn1,netTOAcsIn2,netTOAcsIn3,netTOAcsIn4,netTOAcsIn5,netTOAcsIn6,netTOAcsIn7,netTOAcsIn8,netTOAcsIn9,netTOAcsIn10,netTOAcsIn11),axis=0)\n",
    "\n",
    "#Seperate each precip_index array\n",
    "yIn1=dummy_ystack[0,:,:]\n",
    "yIn2=dummy_ystack[1,:,:]\n",
    "yIn3=dummy_ystack[2,:,:]\n",
    "yIn4=dummy_ystack[3,:,:]\n",
    "yIn5=dummy_ystack[4,:,:]\n",
    "yIn6=dummy_ystack[5,:,:]\n",
    "yIn7=dummy_ystack[6,:,:]\n",
    "yIn8=dummy_ystack[7,:,:]\n",
    "yIn9=dummy_ystack[8,:,:]\n",
    "yIn10=dummy_ystack[9,:,:]\n",
    "yIn11=dummy_ystack[10,:,:]\n",
    "\n",
    "#Concatenate the ensemble members along time axis\n",
    "yIn=np.concatenate((yIn1,yIn2,yIn3,yIn4,yIn5,yIn6,yIn7,yIn8,yIn9,yIn10,yIn11),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "outer-environment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5808, 53, 61, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare Data for CNN\n",
    "cres_train, cres_test, crel_train, crel_test, netTOAcs_train, netTOAcs_test, y_train, y_test = train_test_split(cresIn, crelIn, netTOAcsIn, yIn, stratify=yIn, test_size=0.2, random_state=42)\n",
    "\n",
    "#Add extra dimension to data, required for algorithm\n",
    "crestrain=cres_train[:,:,:,None]\n",
    "creltrain=crel_train[:,:,:,None]\n",
    "netTOAcstrain=netTOAcs_train[:,:,:,None]\n",
    "\n",
    "#---------------------------------------------------------\n",
    "crestest=cres_test[:,:,:,None]\n",
    "creltest=crel_test[:,:,:,None]\n",
    "netTOAcstest=netTOAcs_test[:,:,:,None]\n",
    "\n",
    "X_test=np.array([crestest,creltest,netTOAcstest])\n",
    "X_train=np.array([crestrain,creltrain,netTOAcstrain])\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "X_train_reshape = np.einsum('lkija->klija',X_train)\n",
    "X_train_reshape.shape\n",
    "\n",
    "X_test_reshape = np.einsum('lkija->klija',X_test)\n",
    "X_test_reshape.shape\n",
    "\n",
    "# check for nan\n",
    "np.isnan(X_test_reshape).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "operating-enough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5808, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sealed-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' #To be compatable with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "peaceful-nursery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 4s 20ms/step - loss: 1.4238 - accuracy: 0.3447 - val_loss: 1.0987 - val_accuracy: 0.3322\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.3212 - accuracy: 0.3344 - val_loss: 1.0993 - val_accuracy: 0.3270\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.3028 - accuracy: 0.3256 - val_loss: 1.0999 - val_accuracy: 0.3408\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2611 - accuracy: 0.3348 - val_loss: 1.1010 - val_accuracy: 0.3425\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2400 - accuracy: 0.3461 - val_loss: 1.1032 - val_accuracy: 0.3425\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2456 - accuracy: 0.3314 - val_loss: 1.1071 - val_accuracy: 0.3425\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2150 - accuracy: 0.3337 - val_loss: 1.1141 - val_accuracy: 0.3425\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2042 - accuracy: 0.3333 - val_loss: 1.1230 - val_accuracy: 0.3425\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1952 - accuracy: 0.3352 - val_loss: 1.1344 - val_accuracy: 0.3425\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1794 - accuracy: 0.3350 - val_loss: 1.1465 - val_accuracy: 0.3425\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1702 - accuracy: 0.3417 - val_loss: 1.1602 - val_accuracy: 0.3425\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1607 - accuracy: 0.3447 - val_loss: 1.1728 - val_accuracy: 0.3425\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1553 - accuracy: 0.3482 - val_loss: 1.1833 - val_accuracy: 0.3425\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1542 - accuracy: 0.3426 - val_loss: 1.1901 - val_accuracy: 0.3425\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1457 - accuracy: 0.3461 - val_loss: 1.1954 - val_accuracy: 0.3425\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1313 - accuracy: 0.3513 - val_loss: 1.1996 - val_accuracy: 0.3425\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1392 - accuracy: 0.3377 - val_loss: 1.2058 - val_accuracy: 0.3425\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1375 - accuracy: 0.3306 - val_loss: 1.2117 - val_accuracy: 0.3425\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1344 - accuracy: 0.3354 - val_loss: 1.2162 - val_accuracy: 0.3425\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1267 - accuracy: 0.3488 - val_loss: 1.2201 - val_accuracy: 0.3425\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1183 - accuracy: 0.3574 - val_loss: 1.2195 - val_accuracy: 0.3425\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1231 - accuracy: 0.3482 - val_loss: 1.2214 - val_accuracy: 0.3425\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1243 - accuracy: 0.3373 - val_loss: 1.2201 - val_accuracy: 0.3425\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1162 - accuracy: 0.3511 - val_loss: 1.2204 - val_accuracy: 0.3425\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1199 - accuracy: 0.3440 - val_loss: 1.2218 - val_accuracy: 0.3425\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1199 - accuracy: 0.3413 - val_loss: 1.2242 - val_accuracy: 0.3425\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1143 - accuracy: 0.3482 - val_loss: 1.2275 - val_accuracy: 0.3425\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1175 - accuracy: 0.3407 - val_loss: 1.2268 - val_accuracy: 0.3425\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1129 - accuracy: 0.3509 - val_loss: 1.2279 - val_accuracy: 0.3425\n",
      "Epoch 29: early stopping\n",
      "Score for fold 1: loss of 1.2278610467910767; accuracy of 34.25129055976868%\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 1.3018 - accuracy: 0.3444 - val_loss: 1.0986 - val_accuracy: 0.3201\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2392 - accuracy: 0.3459 - val_loss: 1.0987 - val_accuracy: 0.3236\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 1.2265 - accuracy: 0.3438 - val_loss: 1.0987 - val_accuracy: 0.3219\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2065 - accuracy: 0.3419 - val_loss: 1.0987 - val_accuracy: 0.3253\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1852 - accuracy: 0.3465 - val_loss: 1.0988 - val_accuracy: 0.3339\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1815 - accuracy: 0.3407 - val_loss: 1.0992 - val_accuracy: 0.3339\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1700 - accuracy: 0.3359 - val_loss: 1.0999 - val_accuracy: 0.3373\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1639 - accuracy: 0.3348 - val_loss: 1.1011 - val_accuracy: 0.3408\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1471 - accuracy: 0.3459 - val_loss: 1.1029 - val_accuracy: 0.3322\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 1.1464 - accuracy: 0.3396 - val_loss: 1.1058 - val_accuracy: 0.3322\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1407 - accuracy: 0.3367 - val_loss: 1.1091 - val_accuracy: 0.3219\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1382 - accuracy: 0.3325 - val_loss: 1.1131 - val_accuracy: 0.3201\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 1.1342 - accuracy: 0.3386 - val_loss: 1.1178 - val_accuracy: 0.3201\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1283 - accuracy: 0.3438 - val_loss: 1.1214 - val_accuracy: 0.3201\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1318 - accuracy: 0.3369 - val_loss: 1.1244 - val_accuracy: 0.3201\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1294 - accuracy: 0.3342 - val_loss: 1.1259 - val_accuracy: 0.3184\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1263 - accuracy: 0.3388 - val_loss: 1.1280 - val_accuracy: 0.3184\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1235 - accuracy: 0.3402 - val_loss: 1.1286 - val_accuracy: 0.3184\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1192 - accuracy: 0.3425 - val_loss: 1.1302 - val_accuracy: 0.3184\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1113 - accuracy: 0.3516 - val_loss: 1.1308 - val_accuracy: 0.3236\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1157 - accuracy: 0.3449 - val_loss: 1.1305 - val_accuracy: 0.3167\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1120 - accuracy: 0.3495 - val_loss: 1.1307 - val_accuracy: 0.3167\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1129 - accuracy: 0.3415 - val_loss: 1.1308 - val_accuracy: 0.3339\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1144 - accuracy: 0.3405 - val_loss: 1.1310 - val_accuracy: 0.3322\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1137 - accuracy: 0.3382 - val_loss: 1.1313 - val_accuracy: 0.3322\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1076 - accuracy: 0.3480 - val_loss: 1.1318 - val_accuracy: 0.3270\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1056 - accuracy: 0.3513 - val_loss: 1.1323 - val_accuracy: 0.3391\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1099 - accuracy: 0.3417 - val_loss: 1.1333 - val_accuracy: 0.3373\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 1.1076 - accuracy: 0.3438 - val_loss: 1.1346 - val_accuracy: 0.3322\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1059 - accuracy: 0.3386 - val_loss: 1.1363 - val_accuracy: 0.3391\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1041 - accuracy: 0.3470 - val_loss: 1.1366 - val_accuracy: 0.3477\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1058 - accuracy: 0.3446 - val_loss: 1.1379 - val_accuracy: 0.3373\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1056 - accuracy: 0.3476 - val_loss: 1.1390 - val_accuracy: 0.3408\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1071 - accuracy: 0.3403 - val_loss: 1.1389 - val_accuracy: 0.3425\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1051 - accuracy: 0.3480 - val_loss: 1.1384 - val_accuracy: 0.3528\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1034 - accuracy: 0.3442 - val_loss: 1.1394 - val_accuracy: 0.3528\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1011 - accuracy: 0.3570 - val_loss: 1.1396 - val_accuracy: 0.3580\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 1.1013 - accuracy: 0.3486 - val_loss: 1.1398 - val_accuracy: 0.3546\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1039 - accuracy: 0.3405 - val_loss: 1.1414 - val_accuracy: 0.3563\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1043 - accuracy: 0.3535 - val_loss: 1.1434 - val_accuracy: 0.3546\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1044 - accuracy: 0.3457 - val_loss: 1.1427 - val_accuracy: 0.3528\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1027 - accuracy: 0.3428 - val_loss: 1.1429 - val_accuracy: 0.3580\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1024 - accuracy: 0.3423 - val_loss: 1.1435 - val_accuracy: 0.3563\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1027 - accuracy: 0.3499 - val_loss: 1.1425 - val_accuracy: 0.3546\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1004 - accuracy: 0.3482 - val_loss: 1.1424 - val_accuracy: 0.3528\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1011 - accuracy: 0.3444 - val_loss: 1.1433 - val_accuracy: 0.3563\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1004 - accuracy: 0.3545 - val_loss: 1.1427 - val_accuracy: 0.3563\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 1.0998 - accuracy: 0.3597 - val_loss: 1.1424 - val_accuracy: 0.3649\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.0991 - accuracy: 0.3604 - val_loss: 1.1418 - val_accuracy: 0.3563\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1011 - accuracy: 0.3591 - val_loss: 1.1426 - val_accuracy: 0.3614\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1001 - accuracy: 0.3497 - val_loss: 1.1437 - val_accuracy: 0.3614\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1004 - accuracy: 0.3557 - val_loss: 1.1435 - val_accuracy: 0.3632\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1008 - accuracy: 0.3482 - val_loss: 1.1445 - val_accuracy: 0.3701\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1004 - accuracy: 0.3513 - val_loss: 1.1429 - val_accuracy: 0.3614\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.0989 - accuracy: 0.3537 - val_loss: 1.1437 - val_accuracy: 0.3597\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.0988 - accuracy: 0.3493 - val_loss: 1.1433 - val_accuracy: 0.3597\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.0998 - accuracy: 0.3549 - val_loss: 1.1408 - val_accuracy: 0.3683\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.0993 - accuracy: 0.3480 - val_loss: 1.1401 - val_accuracy: 0.3666\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1003 - accuracy: 0.3388 - val_loss: 1.1397 - val_accuracy: 0.3614\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.0973 - accuracy: 0.3595 - val_loss: 1.1402 - val_accuracy: 0.3666\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1008 - accuracy: 0.3520 - val_loss: 1.1403 - val_accuracy: 0.3528\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.0982 - accuracy: 0.3539 - val_loss: 1.1399 - val_accuracy: 0.3563\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.0998 - accuracy: 0.3528 - val_loss: 1.1401 - val_accuracy: 0.3649\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.0991 - accuracy: 0.3572 - val_loss: 1.1401 - val_accuracy: 0.3597\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.0988 - accuracy: 0.3522 - val_loss: 1.1403 - val_accuracy: 0.3632\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1002 - accuracy: 0.3436 - val_loss: 1.1406 - val_accuracy: 0.3614\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.0962 - accuracy: 0.3587 - val_loss: 1.1407 - val_accuracy: 0.3614\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.0976 - accuracy: 0.3535 - val_loss: 1.1420 - val_accuracy: 0.3597\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.0995 - accuracy: 0.3560 - val_loss: 1.1432 - val_accuracy: 0.3563\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.0972 - accuracy: 0.3612 - val_loss: 1.1441 - val_accuracy: 0.3563\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.0981 - accuracy: 0.3568 - val_loss: 1.1457 - val_accuracy: 0.3563\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.0991 - accuracy: 0.3520 - val_loss: 1.1466 - val_accuracy: 0.3546\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.0981 - accuracy: 0.3585 - val_loss: 1.1462 - val_accuracy: 0.3528\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.0979 - accuracy: 0.3583 - val_loss: 1.1469 - val_accuracy: 0.3546\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1005 - accuracy: 0.3457 - val_loss: 1.1476 - val_accuracy: 0.3546\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.0986 - accuracy: 0.3493 - val_loss: 1.1478 - val_accuracy: 0.3546\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1000 - accuracy: 0.3528 - val_loss: 1.1476 - val_accuracy: 0.3528\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 1.0968 - accuracy: 0.3616 - val_loss: 1.1471 - val_accuracy: 0.3546\n",
      "Epoch 78: early stopping\n",
      "Score for fold 2: loss of 1.1470794677734375; accuracy of 35.456109046936035%\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 1.3566 - accuracy: 0.3545 - val_loss: 1.0985 - val_accuracy: 0.3236\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.2715 - accuracy: 0.3365 - val_loss: 1.0982 - val_accuracy: 0.3373\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2302 - accuracy: 0.3432 - val_loss: 1.0981 - val_accuracy: 0.3201\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2107 - accuracy: 0.3470 - val_loss: 1.0982 - val_accuracy: 0.3115\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.2068 - accuracy: 0.3453 - val_loss: 1.0985 - val_accuracy: 0.3115\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1885 - accuracy: 0.3352 - val_loss: 1.0992 - val_accuracy: 0.3133\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1847 - accuracy: 0.3373 - val_loss: 1.1007 - val_accuracy: 0.3133\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1714 - accuracy: 0.3325 - val_loss: 1.1032 - val_accuracy: 0.3133\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1578 - accuracy: 0.3373 - val_loss: 1.1068 - val_accuracy: 0.3133\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1534 - accuracy: 0.3342 - val_loss: 1.1126 - val_accuracy: 0.3133\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1433 - accuracy: 0.3530 - val_loss: 1.1189 - val_accuracy: 0.3133\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1394 - accuracy: 0.3488 - val_loss: 1.1263 - val_accuracy: 0.3133\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1386 - accuracy: 0.3451 - val_loss: 1.1330 - val_accuracy: 0.3133\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1338 - accuracy: 0.3379 - val_loss: 1.1394 - val_accuracy: 0.3133\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1361 - accuracy: 0.3346 - val_loss: 1.1466 - val_accuracy: 0.3133\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1338 - accuracy: 0.3509 - val_loss: 1.1506 - val_accuracy: 0.3133\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1250 - accuracy: 0.3428 - val_loss: 1.1563 - val_accuracy: 0.3133\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1393 - accuracy: 0.3243 - val_loss: 1.1566 - val_accuracy: 0.3133\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1264 - accuracy: 0.3338 - val_loss: 1.1575 - val_accuracy: 0.3133\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1188 - accuracy: 0.3505 - val_loss: 1.1601 - val_accuracy: 0.3133\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1275 - accuracy: 0.3262 - val_loss: 1.1621 - val_accuracy: 0.3133\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1221 - accuracy: 0.3403 - val_loss: 1.1642 - val_accuracy: 0.3133\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1191 - accuracy: 0.3425 - val_loss: 1.1642 - val_accuracy: 0.3133\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1163 - accuracy: 0.3423 - val_loss: 1.1663 - val_accuracy: 0.3133\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1214 - accuracy: 0.3421 - val_loss: 1.1650 - val_accuracy: 0.3133\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1165 - accuracy: 0.3390 - val_loss: 1.1645 - val_accuracy: 0.3133\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1152 - accuracy: 0.3457 - val_loss: 1.1645 - val_accuracy: 0.3133\n",
      "Epoch 27: early stopping\n",
      "Score for fold 3: loss of 1.1645346879959106; accuracy of 31.32530152797699%\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 1.4608 - accuracy: 0.3338 - val_loss: 1.0990 - val_accuracy: 0.3098\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.3792 - accuracy: 0.3206 - val_loss: 1.0981 - val_accuracy: 0.3322\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.3246 - accuracy: 0.3371 - val_loss: 1.0976 - val_accuracy: 0.3322\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.3149 - accuracy: 0.3250 - val_loss: 1.0970 - val_accuracy: 0.3253\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2814 - accuracy: 0.3365 - val_loss: 1.0967 - val_accuracy: 0.3253\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2468 - accuracy: 0.3417 - val_loss: 1.0966 - val_accuracy: 0.3270\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2405 - accuracy: 0.3329 - val_loss: 1.0970 - val_accuracy: 0.3287\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.2462 - accuracy: 0.3205 - val_loss: 1.0983 - val_accuracy: 0.3322\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.2203 - accuracy: 0.3310 - val_loss: 1.1003 - val_accuracy: 0.3287\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2045 - accuracy: 0.3321 - val_loss: 1.1030 - val_accuracy: 0.3287\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1847 - accuracy: 0.3317 - val_loss: 1.1072 - val_accuracy: 0.3305\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1816 - accuracy: 0.3375 - val_loss: 1.1109 - val_accuracy: 0.3356\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1833 - accuracy: 0.3359 - val_loss: 1.1144 - val_accuracy: 0.3373\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1610 - accuracy: 0.3507 - val_loss: 1.1173 - val_accuracy: 0.3373\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1628 - accuracy: 0.3421 - val_loss: 1.1202 - val_accuracy: 0.3408\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1576 - accuracy: 0.3417 - val_loss: 1.1229 - val_accuracy: 0.3391\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1535 - accuracy: 0.3359 - val_loss: 1.1251 - val_accuracy: 0.3373\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1509 - accuracy: 0.3398 - val_loss: 1.1275 - val_accuracy: 0.3391\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1438 - accuracy: 0.3331 - val_loss: 1.1311 - val_accuracy: 0.3373\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1364 - accuracy: 0.3333 - val_loss: 1.1336 - val_accuracy: 0.3391\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1263 - accuracy: 0.3444 - val_loss: 1.1333 - val_accuracy: 0.3391\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1286 - accuracy: 0.3425 - val_loss: 1.1353 - val_accuracy: 0.3391\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1263 - accuracy: 0.3455 - val_loss: 1.1358 - val_accuracy: 0.3373\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1271 - accuracy: 0.3388 - val_loss: 1.1377 - val_accuracy: 0.3373\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1243 - accuracy: 0.3358 - val_loss: 1.1392 - val_accuracy: 0.3373\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1243 - accuracy: 0.3463 - val_loss: 1.1397 - val_accuracy: 0.3373\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1248 - accuracy: 0.3413 - val_loss: 1.1406 - val_accuracy: 0.3373\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1181 - accuracy: 0.3413 - val_loss: 1.1406 - val_accuracy: 0.3373\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1196 - accuracy: 0.3407 - val_loss: 1.1412 - val_accuracy: 0.3373\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1131 - accuracy: 0.3417 - val_loss: 1.1417 - val_accuracy: 0.3373\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1190 - accuracy: 0.3279 - val_loss: 1.1432 - val_accuracy: 0.3373\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1116 - accuracy: 0.3413 - val_loss: 1.1421 - val_accuracy: 0.3373\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1129 - accuracy: 0.3400 - val_loss: 1.1423 - val_accuracy: 0.3373\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1121 - accuracy: 0.3455 - val_loss: 1.1419 - val_accuracy: 0.3373\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1141 - accuracy: 0.3359 - val_loss: 1.1427 - val_accuracy: 0.3373\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1117 - accuracy: 0.3419 - val_loss: 1.1444 - val_accuracy: 0.3373\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1102 - accuracy: 0.3434 - val_loss: 1.1444 - val_accuracy: 0.3373\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1065 - accuracy: 0.3476 - val_loss: 1.1435 - val_accuracy: 0.3373\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1052 - accuracy: 0.3507 - val_loss: 1.1450 - val_accuracy: 0.3373\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1077 - accuracy: 0.3484 - val_loss: 1.1457 - val_accuracy: 0.3373\n",
      "Epoch 40: early stopping\n",
      "Score for fold 4: loss of 1.1456972360610962; accuracy of 33.73493850231171%\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 1.2886 - accuracy: 0.3411 - val_loss: 1.0987 - val_accuracy: 0.3528\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.2620 - accuracy: 0.3294 - val_loss: 1.0997 - val_accuracy: 0.3442\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2381 - accuracy: 0.3287 - val_loss: 1.1013 - val_accuracy: 0.3442\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2141 - accuracy: 0.3440 - val_loss: 1.1040 - val_accuracy: 0.3442\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2042 - accuracy: 0.3302 - val_loss: 1.1086 - val_accuracy: 0.3442\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.2155 - accuracy: 0.3155 - val_loss: 1.1164 - val_accuracy: 0.3442\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1816 - accuracy: 0.3348 - val_loss: 1.1275 - val_accuracy: 0.3442\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1746 - accuracy: 0.3325 - val_loss: 1.1421 - val_accuracy: 0.3442\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1685 - accuracy: 0.3323 - val_loss: 1.1612 - val_accuracy: 0.3442\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1602 - accuracy: 0.3419 - val_loss: 1.1825 - val_accuracy: 0.3442\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1603 - accuracy: 0.3296 - val_loss: 1.2038 - val_accuracy: 0.3442\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1442 - accuracy: 0.3359 - val_loss: 1.2224 - val_accuracy: 0.3442\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1575 - accuracy: 0.3214 - val_loss: 1.2359 - val_accuracy: 0.3442\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1400 - accuracy: 0.3394 - val_loss: 1.2482 - val_accuracy: 0.3442\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1400 - accuracy: 0.3365 - val_loss: 1.2549 - val_accuracy: 0.3442\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1311 - accuracy: 0.3379 - val_loss: 1.2582 - val_accuracy: 0.3442\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1334 - accuracy: 0.3417 - val_loss: 1.2591 - val_accuracy: 0.3442\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1361 - accuracy: 0.3319 - val_loss: 1.2574 - val_accuracy: 0.3442\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1298 - accuracy: 0.3390 - val_loss: 1.2596 - val_accuracy: 0.3442\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1242 - accuracy: 0.3394 - val_loss: 1.2606 - val_accuracy: 0.3442\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1270 - accuracy: 0.3338 - val_loss: 1.2584 - val_accuracy: 0.3442\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1307 - accuracy: 0.3270 - val_loss: 1.2584 - val_accuracy: 0.3442\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1285 - accuracy: 0.3344 - val_loss: 1.2579 - val_accuracy: 0.3442\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1195 - accuracy: 0.3402 - val_loss: 1.2580 - val_accuracy: 0.3442\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1227 - accuracy: 0.3344 - val_loss: 1.2576 - val_accuracy: 0.3442\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1189 - accuracy: 0.3409 - val_loss: 1.2574 - val_accuracy: 0.3442\n",
      "Epoch 26: early stopping\n",
      "Score for fold 5: loss of 1.2573955059051514; accuracy of 34.42340791225433%\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 1.6696 - accuracy: 0.3417 - val_loss: 1.0986 - val_accuracy: 0.3339\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2705 - accuracy: 0.3294 - val_loss: 1.0983 - val_accuracy: 0.3081\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2186 - accuracy: 0.3285 - val_loss: 1.0983 - val_accuracy: 0.2926\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1821 - accuracy: 0.3516 - val_loss: 1.0987 - val_accuracy: 0.3167\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1840 - accuracy: 0.3434 - val_loss: 1.0999 - val_accuracy: 0.3115\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1668 - accuracy: 0.3465 - val_loss: 1.1023 - val_accuracy: 0.3167\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 1.1712 - accuracy: 0.3457 - val_loss: 1.1065 - val_accuracy: 0.3253\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1530 - accuracy: 0.3444 - val_loss: 1.1126 - val_accuracy: 0.3150\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1518 - accuracy: 0.3342 - val_loss: 1.1216 - val_accuracy: 0.3236\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1487 - accuracy: 0.3375 - val_loss: 1.1329 - val_accuracy: 0.3270\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1425 - accuracy: 0.3281 - val_loss: 1.1463 - val_accuracy: 0.3270\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1345 - accuracy: 0.3344 - val_loss: 1.1598 - val_accuracy: 0.3219\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1339 - accuracy: 0.3436 - val_loss: 1.1721 - val_accuracy: 0.3236\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1341 - accuracy: 0.3338 - val_loss: 1.1820 - val_accuracy: 0.3201\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1301 - accuracy: 0.3400 - val_loss: 1.1889 - val_accuracy: 0.3219\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1273 - accuracy: 0.3377 - val_loss: 1.1947 - val_accuracy: 0.3236\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1327 - accuracy: 0.3247 - val_loss: 1.2003 - val_accuracy: 0.3201\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1226 - accuracy: 0.3369 - val_loss: 1.2049 - val_accuracy: 0.3167\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1272 - accuracy: 0.3331 - val_loss: 1.2086 - val_accuracy: 0.3236\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1187 - accuracy: 0.3350 - val_loss: 1.2088 - val_accuracy: 0.3270\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1191 - accuracy: 0.3394 - val_loss: 1.2127 - val_accuracy: 0.3287\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1157 - accuracy: 0.3421 - val_loss: 1.2142 - val_accuracy: 0.3236\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1205 - accuracy: 0.3287 - val_loss: 1.2178 - val_accuracy: 0.3184\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1167 - accuracy: 0.3442 - val_loss: 1.2179 - val_accuracy: 0.3201\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1097 - accuracy: 0.3423 - val_loss: 1.2184 - val_accuracy: 0.3219\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1137 - accuracy: 0.3327 - val_loss: 1.2202 - val_accuracy: 0.3219\n",
      "Epoch 26: early stopping\n",
      "Score for fold 6: loss of 1.2201582193374634; accuracy of 32.185885310173035%\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 1.4812 - accuracy: 0.3323 - val_loss: 1.0984 - val_accuracy: 0.3460\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.3392 - accuracy: 0.3337 - val_loss: 1.0976 - val_accuracy: 0.3494\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.3002 - accuracy: 0.3247 - val_loss: 1.0987 - val_accuracy: 0.3494\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2720 - accuracy: 0.3342 - val_loss: 1.1025 - val_accuracy: 0.3494\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.2630 - accuracy: 0.3237 - val_loss: 1.1101 - val_accuracy: 0.3494\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2232 - accuracy: 0.3373 - val_loss: 1.1236 - val_accuracy: 0.3494\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2192 - accuracy: 0.3310 - val_loss: 1.1443 - val_accuracy: 0.3494\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2109 - accuracy: 0.3291 - val_loss: 1.1763 - val_accuracy: 0.3494\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 1.1971 - accuracy: 0.3229 - val_loss: 1.2166 - val_accuracy: 0.3494\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1784 - accuracy: 0.3440 - val_loss: 1.2643 - val_accuracy: 0.3494\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1748 - accuracy: 0.3264 - val_loss: 1.3171 - val_accuracy: 0.3494\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1665 - accuracy: 0.3327 - val_loss: 1.3657 - val_accuracy: 0.3494\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1571 - accuracy: 0.3388 - val_loss: 1.4082 - val_accuracy: 0.3494\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1611 - accuracy: 0.3264 - val_loss: 1.4467 - val_accuracy: 0.3494\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1505 - accuracy: 0.3390 - val_loss: 1.4679 - val_accuracy: 0.3494\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1458 - accuracy: 0.3428 - val_loss: 1.4798 - val_accuracy: 0.3494\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1396 - accuracy: 0.3474 - val_loss: 1.4852 - val_accuracy: 0.3494\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1355 - accuracy: 0.3314 - val_loss: 1.4858 - val_accuracy: 0.3494\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1356 - accuracy: 0.3367 - val_loss: 1.4906 - val_accuracy: 0.3494\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1282 - accuracy: 0.3449 - val_loss: 1.4898 - val_accuracy: 0.3494\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1356 - accuracy: 0.3323 - val_loss: 1.4856 - val_accuracy: 0.3494\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1254 - accuracy: 0.3507 - val_loss: 1.4859 - val_accuracy: 0.3494\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1289 - accuracy: 0.3271 - val_loss: 1.4835 - val_accuracy: 0.3494\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1228 - accuracy: 0.3430 - val_loss: 1.4812 - val_accuracy: 0.3494\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1190 - accuracy: 0.3484 - val_loss: 1.4761 - val_accuracy: 0.3494\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1182 - accuracy: 0.3440 - val_loss: 1.4712 - val_accuracy: 0.3494\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1185 - accuracy: 0.3449 - val_loss: 1.4646 - val_accuracy: 0.3494\n",
      "Epoch 27: early stopping\n",
      "Score for fold 7: loss of 1.464606523513794; accuracy of 34.939759969711304%\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 1.3178 - accuracy: 0.3526 - val_loss: 1.0984 - val_accuracy: 0.3356\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2920 - accuracy: 0.3258 - val_loss: 1.0979 - val_accuracy: 0.3546\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2406 - accuracy: 0.3551 - val_loss: 1.0977 - val_accuracy: 0.3563\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2404 - accuracy: 0.3392 - val_loss: 1.0976 - val_accuracy: 0.3528\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 1.2247 - accuracy: 0.3384 - val_loss: 1.0977 - val_accuracy: 0.3528\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2087 - accuracy: 0.3329 - val_loss: 1.0981 - val_accuracy: 0.3528\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1939 - accuracy: 0.3400 - val_loss: 1.0990 - val_accuracy: 0.3528\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1810 - accuracy: 0.3348 - val_loss: 1.1009 - val_accuracy: 0.3528\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1721 - accuracy: 0.3373 - val_loss: 1.1038 - val_accuracy: 0.3528\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1627 - accuracy: 0.3413 - val_loss: 1.1073 - val_accuracy: 0.3528\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1615 - accuracy: 0.3306 - val_loss: 1.1121 - val_accuracy: 0.3528\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1518 - accuracy: 0.3396 - val_loss: 1.1165 - val_accuracy: 0.3528\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1491 - accuracy: 0.3283 - val_loss: 1.1197 - val_accuracy: 0.3528\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1384 - accuracy: 0.3415 - val_loss: 1.1232 - val_accuracy: 0.3528\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1367 - accuracy: 0.3350 - val_loss: 1.1266 - val_accuracy: 0.3528\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1346 - accuracy: 0.3371 - val_loss: 1.1288 - val_accuracy: 0.3528\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1331 - accuracy: 0.3363 - val_loss: 1.1320 - val_accuracy: 0.3528\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1260 - accuracy: 0.3398 - val_loss: 1.1333 - val_accuracy: 0.3528\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1265 - accuracy: 0.3359 - val_loss: 1.1349 - val_accuracy: 0.3528\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1218 - accuracy: 0.3419 - val_loss: 1.1356 - val_accuracy: 0.3528\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1212 - accuracy: 0.3426 - val_loss: 1.1380 - val_accuracy: 0.3528\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1193 - accuracy: 0.3434 - val_loss: 1.1386 - val_accuracy: 0.3528\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1222 - accuracy: 0.3337 - val_loss: 1.1402 - val_accuracy: 0.3528\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1193 - accuracy: 0.3377 - val_loss: 1.1415 - val_accuracy: 0.3528\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1125 - accuracy: 0.3447 - val_loss: 1.1436 - val_accuracy: 0.3528\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1167 - accuracy: 0.3281 - val_loss: 1.1436 - val_accuracy: 0.3528\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1152 - accuracy: 0.3461 - val_loss: 1.1452 - val_accuracy: 0.3528\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1152 - accuracy: 0.3310 - val_loss: 1.1462 - val_accuracy: 0.3528\n",
      "Epoch 28: early stopping\n",
      "Score for fold 8: loss of 1.146190881729126; accuracy of 35.28399169445038%\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 2s 19ms/step - loss: 1.3672 - accuracy: 0.3307 - val_loss: 1.0988 - val_accuracy: 0.3138\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2940 - accuracy: 0.3441 - val_loss: 1.0983 - val_accuracy: 0.3569\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2629 - accuracy: 0.3393 - val_loss: 1.0982 - val_accuracy: 0.3534\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2400 - accuracy: 0.3401 - val_loss: 1.0982 - val_accuracy: 0.3534\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2282 - accuracy: 0.3363 - val_loss: 1.0985 - val_accuracy: 0.3534\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2049 - accuracy: 0.3487 - val_loss: 1.0991 - val_accuracy: 0.3534\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2009 - accuracy: 0.3370 - val_loss: 1.1002 - val_accuracy: 0.3534\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1999 - accuracy: 0.3261 - val_loss: 1.1018 - val_accuracy: 0.3534\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1773 - accuracy: 0.3403 - val_loss: 1.1042 - val_accuracy: 0.3534\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1705 - accuracy: 0.3412 - val_loss: 1.1067 - val_accuracy: 0.3534\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1632 - accuracy: 0.3324 - val_loss: 1.1092 - val_accuracy: 0.3534\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1534 - accuracy: 0.3422 - val_loss: 1.1122 - val_accuracy: 0.3534\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1490 - accuracy: 0.3453 - val_loss: 1.1142 - val_accuracy: 0.3534\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1529 - accuracy: 0.3397 - val_loss: 1.1162 - val_accuracy: 0.3534\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1468 - accuracy: 0.3372 - val_loss: 1.1171 - val_accuracy: 0.3534\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1376 - accuracy: 0.3462 - val_loss: 1.1173 - val_accuracy: 0.3534\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1387 - accuracy: 0.3449 - val_loss: 1.1178 - val_accuracy: 0.3534\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1381 - accuracy: 0.3393 - val_loss: 1.1180 - val_accuracy: 0.3534\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1298 - accuracy: 0.3449 - val_loss: 1.1169 - val_accuracy: 0.3534\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1240 - accuracy: 0.3476 - val_loss: 1.1171 - val_accuracy: 0.3534\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1280 - accuracy: 0.3395 - val_loss: 1.1174 - val_accuracy: 0.3534\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1282 - accuracy: 0.3435 - val_loss: 1.1174 - val_accuracy: 0.3534\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1187 - accuracy: 0.3458 - val_loss: 1.1177 - val_accuracy: 0.3534\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1175 - accuracy: 0.3472 - val_loss: 1.1171 - val_accuracy: 0.3534\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1197 - accuracy: 0.3405 - val_loss: 1.1171 - val_accuracy: 0.3534\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1189 - accuracy: 0.3391 - val_loss: 1.1174 - val_accuracy: 0.3534\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1134 - accuracy: 0.3573 - val_loss: 1.1175 - val_accuracy: 0.3534\n",
      "Epoch 27: early stopping\n",
      "Score for fold 9: loss of 1.117463231086731; accuracy of 35.34482717514038%\n",
      "Epoch 1/100\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 1.4150 - accuracy: 0.3351 - val_loss: 1.0984 - val_accuracy: 0.3448\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.3054 - accuracy: 0.3349 - val_loss: 1.0991 - val_accuracy: 0.3138\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2898 - accuracy: 0.3292 - val_loss: 1.1000 - val_accuracy: 0.3052\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2600 - accuracy: 0.3345 - val_loss: 1.1010 - val_accuracy: 0.3086\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2321 - accuracy: 0.3393 - val_loss: 1.1024 - val_accuracy: 0.3086\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2233 - accuracy: 0.3275 - val_loss: 1.1045 - val_accuracy: 0.3086\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2136 - accuracy: 0.3242 - val_loss: 1.1076 - val_accuracy: 0.3086\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.2022 - accuracy: 0.3324 - val_loss: 1.1116 - val_accuracy: 0.3086\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 1.1806 - accuracy: 0.3319 - val_loss: 1.1165 - val_accuracy: 0.3086\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1756 - accuracy: 0.3305 - val_loss: 1.1225 - val_accuracy: 0.3086\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1606 - accuracy: 0.3317 - val_loss: 1.1295 - val_accuracy: 0.3086\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1577 - accuracy: 0.3322 - val_loss: 1.1368 - val_accuracy: 0.3086\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1458 - accuracy: 0.3300 - val_loss: 1.1433 - val_accuracy: 0.3086\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1410 - accuracy: 0.3407 - val_loss: 1.1486 - val_accuracy: 0.3086\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1346 - accuracy: 0.3416 - val_loss: 1.1520 - val_accuracy: 0.3086\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1360 - accuracy: 0.3366 - val_loss: 1.1546 - val_accuracy: 0.3086\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1252 - accuracy: 0.3445 - val_loss: 1.1555 - val_accuracy: 0.3086\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1228 - accuracy: 0.3468 - val_loss: 1.1583 - val_accuracy: 0.3086\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1244 - accuracy: 0.3458 - val_loss: 1.1609 - val_accuracy: 0.3086\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1254 - accuracy: 0.3399 - val_loss: 1.1592 - val_accuracy: 0.3086\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1246 - accuracy: 0.3370 - val_loss: 1.1606 - val_accuracy: 0.3086\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1188 - accuracy: 0.3420 - val_loss: 1.1625 - val_accuracy: 0.3086\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1152 - accuracy: 0.3489 - val_loss: 1.1612 - val_accuracy: 0.3086\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 1.1155 - accuracy: 0.3466 - val_loss: 1.1622 - val_accuracy: 0.3086\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1176 - accuracy: 0.3410 - val_loss: 1.1627 - val_accuracy: 0.3086\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 1.1188 - accuracy: 0.3344 - val_loss: 1.1627 - val_accuracy: 0.3086\n",
      "Epoch 26: early stopping\n",
      "Score for fold 10: loss of 1.1626758575439453; accuracy of 30.862069129943848%\n"
     ]
    }
   ],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu', padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(MaxPooling3D(padding='same'))\n",
    "    cnn3.add(Dropout(rate=0.4))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(padding='same'))\n",
    "    cnn3.add(Dropout(rate=0.4))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(padding='same'))\n",
    "    cnn3.add(Dropout(rate=0.4))\n",
    "    \n",
    "    cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(padding='same'))\n",
    "    cnn3.add(Dropout(rate=0.4))\n",
    "    \n",
    "    cnn3.add(Conv3D(128, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(BatchNormalization())\n",
    "    cnn3.add(MaxPooling3D(padding='same'))\n",
    "    cnn3.add(Dropout(rate=0.4))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=25)\n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(512, activation='relu'))\n",
    "    cnn3.add(Dense(64, activation='relu'))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= 3, activation = 'softmax')) #units is always equal to number of classes\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.00001) # learning_rate\n",
    "    sgd=keras.optimizers.SGD(lr=0.0001)\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=100 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  batch_size=100, epochs=epochs, verbose=1, shuffle=True, callbacks=[es],\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    #gc.collect()\n",
    "    #K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tight-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cnn3.predict((X_train_reshape), batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "olympic-exercise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5808, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "impossible-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.argmax ( pred , axis=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "neural-marketplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "[2 0 2 ... 0 0 0]\n",
      "1873 out of 5808\n"
     ]
    }
   ],
   "source": [
    "print(predicted)\n",
    "y_true=np.argmax (y_train , axis=-1 )\n",
    "print(y_true)\n",
    "\n",
    "cnt=0\n",
    "for i,p in enumerate(predicted):\n",
    "    if (p==y_true[i]):\n",
    "        cnt=cnt+1\n",
    "\n",
    "#print(cnt, 'out of 201')\n",
    "print(cnt,'out of 5808')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "precious-hobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "[2 2 2 ... 0 0 0]\n",
      "468 out of 1452\n"
     ]
    }
   ],
   "source": [
    "pred_test = cnn3.predict(X_test_reshape, batch_size=10)\n",
    "ytestPred=np.argmax ( pred_test , axis=-1 )\n",
    "ytruePred=np.argmax ( y_test , axis=-1 )\n",
    "print(ytestPred)\n",
    "print(ytruePred)\n",
    "\n",
    "cnt=0\n",
    "for i,p in enumerate(ytestPred):\n",
    "    if (p==ytruePred[i]):\n",
    "        cnt=cnt+1\n",
    "\n",
    "#print(cnt,'out of 51')\n",
    "print(cnt, 'out of 1452')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "completed-mandate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         0\n",
      "           1      1.000     0.322     0.487      1452\n",
      "           2      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.322      1452\n",
      "   macro avg      0.333     0.107     0.162      1452\n",
      "weighted avg      1.000     0.322     0.487      1452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print the confusion matrix\n",
    "#print(metrics.confusion_matrix(ytestPred,ytruePred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(ytestPred,ytruePred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "proper-jersey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'], label='train')\n",
    "plt.plot(hist.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-breathing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-weekend",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-liquid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-assistant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-distributor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-operation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-subdivision",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-selection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-solid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu', padding='same',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                    bias_regularizer=regularizers.l2(1e-4),\n",
    "                    activity_regularizer=regularizers.l2(1e-5),\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(MaxPooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(16, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.2))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=1e-4) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=100 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-commander",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-collect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-feelings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "monthly-solid",
   "metadata": {},
   "source": [
    "# Change to sheet 3 on google sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-flight",
   "metadata": {},
   "source": [
    "# Models 1,2,3 (change epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "        \n",
    "# Define 10-fold cross validation test harness\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(8, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=10 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "        \n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=10, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-words",
   "metadata": {},
   "source": [
    "# Models 4, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    \n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu', padding='same',  kernel_regularizer=regularizers.l2(l=0.01),\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same',  kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    #cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same',  kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    #cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(8, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #sgd=keras.optimizers.SGD(lr=0.0001)\n",
    "    #adadelta=keras.optimizers.Adadelta(learning_rate=0.001)\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=100 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test],y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-warehouse",
   "metadata": {},
   "source": [
    "# Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    \n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=3, activation='relu', padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    #cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same',  kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    #cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.4))\n",
    "    \n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(8, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.2))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #sgd=keras.optimizers.SGD(lr=0.0001)\n",
    "    #adadelta=keras.optimizers.Adadelta(learning_rate=0.001)\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=100 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, batch_size=20, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test],y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-creativity",
   "metadata": {},
   "source": [
    "# Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "#To limit memory usage and avoid resource exhaustion\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)  \n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(16, kernel_size=3, activation='relu', padding='same',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                    bias_regularizer=regularizers.l2(1e-4),\n",
    "                    activity_regularizer=regularizers.l2(1e-5),\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    #cnn3.add(Conv3D(16, kernel_size=3, activation='relu',padding='same'))\n",
    "    #cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    #cnn3.add(Conv3D(32, kernel_size=3, activation='relu',padding='same'))\n",
    "    #cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    #cnn3.add(Conv3D(64, kernel_size=3, activation='relu',padding='same'))\n",
    "    #cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    #cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=1e-4) # learning_rate\n",
    "    #sgd=keras.optimizers.SGD(lr=0.0001)\n",
    "    #adadelta=keras.optimizers.Adadelta(learning_rate=0.001)\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=100 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #To prevent resource exhaustion\n",
    "    gc.collect()\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-quantity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-techno",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-difference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-taxation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-inside",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-adoption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-account",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-hobby",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-plenty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-slovak",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-cinema",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_gpu",
   "language": "python",
   "name": "test_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
